{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjOZZ0i9HgvE"
   },
   "source": [
    "# CSC-180 Mini-Project 3: Computer Vision Using GPU and Transfer Learning\n",
    "In this project, our team examined the outcome of training two different computer vision image classification models in order to read and predict images from the CIFAR-10 dataset, which is included with TensorFlow. We provide solutions for two different approaches: a standard convolutional neural network directly using the CIFAR-10 dataset, and a transfer learning model based on the pre-trained VGG16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "yqpcX5h_ci_v"
   },
   "outputs": [],
   "source": [
    "# Noah Venethongkham, 219660117\n",
    "# Ashley Thor, 219334909\n",
    "# Lucas Saechao, 218794239\n",
    "# CSC 180 - Intelligent Systems\n",
    "# Mini-Project 3\n",
    "# April 2, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40YQLAIacTFx"
   },
   "source": [
    "# TensorFlow Helper Functions\n",
    "The following functions assist with data preprocessing: specifically, they are used to build our feature vector.\n",
    "\n",
    "##Predictors and Input\n",
    "* **missing_median(df, name)**\n",
    " * If an input is missing, this function will replace it with the median value from that column.\n",
    "* **encode_text_dummy(df, name)**\n",
    " * This function is used to encode textual or categorical values.\n",
    "* **encode_numeric_zscore(df, name, mean, sd)**\n",
    " * This function is used to encode numeric values.\n",
    " \n",
    "## Output\n",
    "* **encode_text_index(df, name)**\n",
    " * This function is used to encode textual or categorical output values.\n",
    "* **to_xy(df, target)**\n",
    " * This function is used to produce a final feature vector along with an expected output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "HB_jeICyN7jf"
   },
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# scikit learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import column_or_1d\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import skimage.transform\n",
    "\n",
    "\n",
    "# tensorflow and keras\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# python libraries\n",
    "import requests\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import io\n",
    "import os\n",
    "\n",
    "# if OS is windows, import chime\n",
    "if os.name == 'nt':\n",
    "    import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "kPXAp9XdBNqm"
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "import tensorflow as tf\n",
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "UBtdDAt6S4B2"
   },
   "outputs": [],
   "source": [
    "# Plots a confusion matrix for the model\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# Plot an ROC curve\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_area_under_curve = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = $0.2f)' % roc_area_under_curve)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show\n",
    "    \n",
    "# Encodes text values into numerical variables\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for i in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, i)\n",
    "        df[dummy_name] = dummies[i]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "# Normalizes numerical values into a z-score\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "    \n",
    "# For formatting time\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "    \n",
    "# Beep if on a windows machine\n",
    "if os.name == 'nt':\n",
    "    def ding():\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)\n",
    "        winsound.Beep(2000, 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZFnrDX_HsHg"
   },
   "source": [
    "## Switch and Verify GPU\n",
    "To enable GPU backend for your notebook. Runtime->Change runtime type->Hardware Accelerator->GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "5GKoPL85Hv2X",
    "outputId": "aa6a4bba-2495-4d48-d1ab-68d474f64d52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvD3eGg0H3Bs"
   },
   "source": [
    "The above cell should output '/device:GPU:0' in order to verify that this notebook is using the GPU backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzQGz_q1H8Ga"
   },
   "source": [
    "## Part I:   Image classification without transfer learning\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "GHxNpAviHxm0"
   },
   "outputs": [],
   "source": [
    "#  Load cifar-10 data and split it to training and test\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# The data split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiYabRp8H-VS",
    "outputId": "3a3828ed-0c5c-4dab-fbbd-a8ec3af6eab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# print out data shape\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9vN3m6YXH_VR",
    "outputId": "48496c9f-a620-4daa-f054-44e38cc1fa0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[100 168 231]\n",
      "  [100 168 229]\n",
      "  [101 167 230]\n",
      "  ...\n",
      "  [ 95 165 231]\n",
      "  [ 94 165 228]\n",
      "  [ 95 167 229]]\n",
      "\n",
      " [[103 170 230]\n",
      "  [103 168 228]\n",
      "  [104 168 226]\n",
      "  ...\n",
      "  [ 97 167 229]\n",
      "  [ 97 166 227]\n",
      "  [ 97 168 229]]\n",
      "\n",
      " [[107 174 233]\n",
      "  [106 172 230]\n",
      "  [106 173 229]\n",
      "  ...\n",
      "  [100 170 230]\n",
      "  [100 170 230]\n",
      "  [101 172 232]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[165 178 177]\n",
      "  [159 170 167]\n",
      "  [167 177 170]\n",
      "  ...\n",
      "  [ 75 117 154]\n",
      "  [ 75 120 157]\n",
      "  [ 72 120 158]]\n",
      "\n",
      " [[158 174 172]\n",
      "  [173 186 182]\n",
      "  [182 193 188]\n",
      "  ...\n",
      "  [ 76 119 154]\n",
      "  [ 75 119 153]\n",
      "  [ 77 121 154]]\n",
      "\n",
      " [[161 176 174]\n",
      "  [162 176 172]\n",
      "  [160 171 169]\n",
      "  ...\n",
      "  [ 98 137 167]\n",
      "  [129 160 183]\n",
      "  [162 185 202]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x209775a8088>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print image as numpy array\n",
    "print(\"array({})\".format(x_train[15]))\n",
    "\n",
    "# print image\n",
    "plt.imshow(x_train[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "wOe3Vng8ICYZ"
   },
   "outputs": [],
   "source": [
    "# Convert y_train and y_test from 2D to 1D \n",
    "y_train = y_train.reshape(50000)\n",
    "y_test = y_test.reshape(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZTXEvymIDlH",
    "outputId": "9719b214-8655-4f7c-f91e-35a1bce42c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# print y_train/y_test shape\n",
    "# expected: (50000,)\n",
    "# expected: (10000,)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "MZoKgHxFIV46"
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to one hot format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "cgb_BdheIWnW"
   },
   "outputs": [],
   "source": [
    "# Convert data from int to float and normalize it\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV_nUFlZg1e-"
   },
   "source": [
    "## Finding the best model\n",
    "The following code algorithmically attempts to determine which combination of activations, optimizers, and neuron counts will produce the best performing model, in terms of F1 Score.\n",
    "\n",
    "The information about this model is saved to the tuple `best_model`, which contains:\n",
    "* F1 Score\n",
    "* Model\n",
    "* Neuron Count\n",
    "* (Activation, Optimizer)\n",
    "\n",
    "This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IErX0cCIZnj",
    "outputId": "df1692e2-d2d1-4d4c-e2c3-712eb7befb94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:39.98\n",
      "Accuracy: 0.7156\n",
      "F1 Score: 0.714287503877546\n",
      "Layer One: 32\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.75      1000\n",
      "           1       0.83      0.82      0.83      1000\n",
      "           2       0.64      0.61      0.62      1000\n",
      "           3       0.52      0.47      0.50      1000\n",
      "           4       0.66      0.69      0.68      1000\n",
      "           5       0.60      0.62      0.61      1000\n",
      "           6       0.72      0.83      0.77      1000\n",
      "           7       0.78      0.76      0.77      1000\n",
      "           8       0.82      0.83      0.82      1000\n",
      "           9       0.78      0.80      0.79      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.71      0.72      0.71     10000\n",
      "weighted avg       0.71      0.72      0.71     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.714287503877546\n",
      "layer one neurons: 32\n",
      "layer two neurons: 16\n",
      "[BEST MODEL UPDATED] F1 Score: 0.7156\n",
      "[BEST MODEL UPDATED] Hyperparameters: (relu, adam)\n",
      "Elapsed time: 0:00:38.75\n",
      "Accuracy: 0.7324\n",
      "F1 Score: 0.7339083518282432\n",
      "Layer One: 32\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.86      0.82      0.84      1000\n",
      "           2       0.59      0.70      0.64      1000\n",
      "           3       0.53      0.57      0.55      1000\n",
      "           4       0.70      0.70      0.70      1000\n",
      "           5       0.65      0.59      0.62      1000\n",
      "           6       0.80      0.80      0.80      1000\n",
      "           7       0.83      0.74      0.78      1000\n",
      "           8       0.83      0.84      0.84      1000\n",
      "           9       0.80      0.81      0.80      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7339083518282432\n",
      "layer one neurons: 32\n",
      "layer two neurons: 32\n",
      "[BEST MODEL UPDATED] F1 Score: 0.7324\n",
      "[BEST MODEL UPDATED] Hyperparameters: (relu, adam)\n",
      "Elapsed time: 0:00:40.35\n",
      "Accuracy: 0.7401\n",
      "F1 Score: 0.7405678091486606\n",
      "Layer One: 32\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78      1000\n",
      "           1       0.83      0.85      0.84      1000\n",
      "           2       0.66      0.65      0.66      1000\n",
      "           3       0.57      0.55      0.56      1000\n",
      "           4       0.68      0.70      0.69      1000\n",
      "           5       0.62      0.68      0.65      1000\n",
      "           6       0.79      0.80      0.80      1000\n",
      "           7       0.78      0.77      0.78      1000\n",
      "           8       0.90      0.79      0.84      1000\n",
      "           9       0.81      0.82      0.82      1000\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7405678091486606\n",
      "layer one neurons: 32\n",
      "layer two neurons: 64\n",
      "[BEST MODEL UPDATED] F1 Score: 0.7401\n",
      "[BEST MODEL UPDATED] Hyperparameters: (relu, adam)\n",
      "Epoch 00013: early stopping\n",
      "Elapsed time: 0:00:37.08\n",
      "Accuracy: 0.7561\n",
      "F1 Score: 0.7542083719308718\n",
      "Layer One: 32\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1000\n",
      "           1       0.84      0.90      0.87      1000\n",
      "           2       0.75      0.59      0.66      1000\n",
      "           3       0.60      0.57      0.58      1000\n",
      "           4       0.70      0.73      0.71      1000\n",
      "           5       0.65      0.65      0.65      1000\n",
      "           6       0.75      0.86      0.80      1000\n",
      "           7       0.78      0.78      0.78      1000\n",
      "           8       0.88      0.84      0.86      1000\n",
      "           9       0.82      0.84      0.83      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.75     10000\n",
      "weighted avg       0.76      0.76      0.75     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7542083719308718\n",
      "layer one neurons: 32\n",
      "layer two neurons: 128\n",
      "[BEST MODEL UPDATED] F1 Score: 0.7561\n",
      "[BEST MODEL UPDATED] Hyperparameters: (relu, adam)\n",
      "Elapsed time: 0:00:40.38\n",
      "Accuracy: 0.7267\n",
      "F1 Score: 0.7243251279450851\n",
      "Layer One: 64\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1000\n",
      "           1       0.77      0.87      0.82      1000\n",
      "           2       0.69      0.58      0.63      1000\n",
      "           3       0.55      0.53      0.54      1000\n",
      "           4       0.68      0.67      0.68      1000\n",
      "           5       0.64      0.62      0.63      1000\n",
      "           6       0.76      0.86      0.81      1000\n",
      "           7       0.73      0.79      0.76      1000\n",
      "           8       0.82      0.85      0.83      1000\n",
      "           9       0.82      0.77      0.80      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.73      0.72     10000\n",
      "weighted avg       0.73      0.73      0.72     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7243251279450851\n",
      "layer one neurons: 64\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:41.23\n",
      "Accuracy: 0.7352\n",
      "F1 Score: 0.7357340148021856\n",
      "Layer One: 64\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79      1000\n",
      "           1       0.86      0.82      0.84      1000\n",
      "           2       0.66      0.62      0.64      1000\n",
      "           3       0.53      0.58      0.56      1000\n",
      "           4       0.67      0.76      0.71      1000\n",
      "           5       0.63      0.61      0.62      1000\n",
      "           6       0.74      0.84      0.79      1000\n",
      "           7       0.86      0.71      0.78      1000\n",
      "           8       0.82      0.87      0.84      1000\n",
      "           9       0.82      0.78      0.80      1000\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7357340148021856\n",
      "layer one neurons: 64\n",
      "layer two neurons: 32\n",
      "Epoch 00014: early stopping\n",
      "Elapsed time: 0:00:39.87\n",
      "Accuracy: 0.7518\n",
      "F1 Score: 0.753552972193778\n",
      "Layer One: 64\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77      1000\n",
      "           1       0.89      0.83      0.86      1000\n",
      "           2       0.69      0.64      0.67      1000\n",
      "           3       0.53      0.62      0.57      1000\n",
      "           4       0.69      0.73      0.71      1000\n",
      "           5       0.65      0.65      0.65      1000\n",
      "           6       0.83      0.80      0.82      1000\n",
      "           7       0.77      0.82      0.79      1000\n",
      "           8       0.87      0.85      0.86      1000\n",
      "           9       0.82      0.85      0.83      1000\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.75      0.75     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.753552972193778\n",
      "layer one neurons: 64\n",
      "layer two neurons: 64\n",
      "Epoch 00014: early stopping\n",
      "Elapsed time: 0:00:44.12\n",
      "Accuracy: 0.7599\n",
      "F1 Score: 0.7608758291352052\n",
      "Layer One: 64\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1000\n",
      "           1       0.90      0.81      0.85      1000\n",
      "           2       0.74      0.65      0.69      1000\n",
      "           3       0.54      0.63      0.58      1000\n",
      "           4       0.72      0.70      0.71      1000\n",
      "           5       0.65      0.64      0.65      1000\n",
      "           6       0.85      0.80      0.82      1000\n",
      "           7       0.79      0.81      0.80      1000\n",
      "           8       0.86      0.87      0.86      1000\n",
      "           9       0.80      0.87      0.83      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7608758291352052\n",
      "layer one neurons: 64\n",
      "layer two neurons: 128\n",
      "[BEST MODEL UPDATED] F1 Score: 0.7599\n",
      "[BEST MODEL UPDATED] Hyperparameters: (relu, adam)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:45.21\n",
      "Accuracy: 0.7334\n",
      "F1 Score: 0.732037108046693\n",
      "Layer One: 128\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      1000\n",
      "           1       0.82      0.86      0.84      1000\n",
      "           2       0.64      0.64      0.64      1000\n",
      "           3       0.58      0.52      0.55      1000\n",
      "           4       0.70      0.65      0.68      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.76      0.84      0.80      1000\n",
      "           7       0.80      0.77      0.79      1000\n",
      "           8       0.83      0.84      0.83      1000\n",
      "           9       0.87      0.76      0.81      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.73      0.73     10000\n",
      "weighted avg       0.73      0.73      0.73     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.732037108046693\n",
      "layer one neurons: 128\n",
      "layer two neurons: 16\n",
      "Epoch 00014: early stopping\n",
      "Elapsed time: 0:00:42.52\n",
      "Accuracy: 0.7484\n",
      "F1 Score: 0.7480728968150179\n",
      "Layer One: 128\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      1000\n",
      "           1       0.85      0.86      0.86      1000\n",
      "           2       0.67      0.64      0.65      1000\n",
      "           3       0.57      0.53      0.55      1000\n",
      "           4       0.67      0.73      0.69      1000\n",
      "           5       0.63      0.69      0.66      1000\n",
      "           6       0.79      0.83      0.81      1000\n",
      "           7       0.84      0.74      0.79      1000\n",
      "           8       0.86      0.86      0.86      1000\n",
      "           9       0.81      0.83      0.82      1000\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.75     10000\n",
      "weighted avg       0.75      0.75      0.75     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7480728968150179\n",
      "layer one neurons: 128\n",
      "layer two neurons: 32\n",
      "Epoch 00012: early stopping\n",
      "Elapsed time: 0:00:38.47\n",
      "Accuracy: 0.7642\n",
      "F1 Score: 0.7643428431730603\n",
      "Layer One: 128\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81      1000\n",
      "           1       0.85      0.88      0.86      1000\n",
      "           2       0.75      0.64      0.69      1000\n",
      "           3       0.57      0.62      0.59      1000\n",
      "           4       0.74      0.70      0.72      1000\n",
      "           5       0.64      0.69      0.66      1000\n",
      "           6       0.82      0.82      0.82      1000\n",
      "           7       0.83      0.77      0.80      1000\n",
      "           8       0.85      0.88      0.86      1000\n",
      "           9       0.84      0.82      0.83      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7643428431730603\n",
      "layer one neurons: 128\n",
      "layer two neurons: 64\n",
      "[BEST MODEL UPDATED] F1 Score: 0.7642\n",
      "[BEST MODEL UPDATED] Hyperparameters: (relu, adam)\n",
      "Epoch 00012: early stopping\n",
      "Elapsed time: 0:00:42.20\n",
      "Accuracy: 0.7647\n",
      "F1 Score: 0.7638813631049819\n",
      "Layer One: 128\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      1000\n",
      "           1       0.86      0.88      0.87      1000\n",
      "           2       0.72      0.63      0.67      1000\n",
      "           3       0.60      0.58      0.59      1000\n",
      "           4       0.70      0.77      0.73      1000\n",
      "           5       0.66      0.67      0.67      1000\n",
      "           6       0.83      0.80      0.81      1000\n",
      "           7       0.83      0.79      0.81      1000\n",
      "           8       0.89      0.82      0.85      1000\n",
      "           9       0.80      0.88      0.83      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7638813631049819\n",
      "layer one neurons: 128\n",
      "layer two neurons: 128\n",
      "Epoch 00014: early stopping\n",
      "Elapsed time: 0:00:49.69\n",
      "Accuracy: 0.7321\n",
      "F1 Score: 0.7284979677534393\n",
      "Layer One: 256\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77      1000\n",
      "           1       0.87      0.83      0.85      1000\n",
      "           2       0.65      0.58      0.62      1000\n",
      "           3       0.57      0.53      0.55      1000\n",
      "           4       0.63      0.72      0.67      1000\n",
      "           5       0.74      0.52      0.61      1000\n",
      "           6       0.77      0.81      0.79      1000\n",
      "           7       0.75      0.80      0.77      1000\n",
      "           8       0.82      0.85      0.83      1000\n",
      "           9       0.77      0.87      0.81      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.73      0.73     10000\n",
      "weighted avg       0.73      0.73      0.73     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7284979677534393\n",
      "layer one neurons: 256\n",
      "layer two neurons: 16\n",
      "Epoch 00013: early stopping\n",
      "Elapsed time: 0:00:47.62\n",
      "Accuracy: 0.7534\n",
      "F1 Score: 0.7523677876601922\n",
      "Layer One: 256\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79      1000\n",
      "           1       0.89      0.83      0.86      1000\n",
      "           2       0.68      0.66      0.67      1000\n",
      "           3       0.63      0.48      0.54      1000\n",
      "           4       0.68      0.76      0.72      1000\n",
      "           5       0.60      0.72      0.66      1000\n",
      "           6       0.83      0.80      0.81      1000\n",
      "           7       0.79      0.79      0.79      1000\n",
      "           8       0.86      0.86      0.86      1000\n",
      "           9       0.84      0.82      0.83      1000\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.76      0.75      0.75     10000\n",
      "weighted avg       0.76      0.75      0.75     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7523677876601922\n",
      "layer one neurons: 256\n",
      "layer two neurons: 32\n",
      "Epoch 00011: early stopping\n",
      "Elapsed time: 0:00:41.58\n",
      "Accuracy: 0.7642\n",
      "F1 Score: 0.7639760398288359\n",
      "Layer One: 256\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      1000\n",
      "           1       0.86      0.89      0.88      1000\n",
      "           2       0.71      0.63      0.67      1000\n",
      "           3       0.59      0.58      0.58      1000\n",
      "           4       0.70      0.74      0.72      1000\n",
      "           5       0.66      0.70      0.68      1000\n",
      "           6       0.85      0.79      0.82      1000\n",
      "           7       0.78      0.82      0.80      1000\n",
      "           8       0.87      0.87      0.87      1000\n",
      "           9       0.88      0.79      0.83      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.76      0.76     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.7639760398288359\n",
      "layer one neurons: 256\n",
      "layer two neurons: 64\n",
      "Epoch 00011: early stopping\n",
      "Elapsed time: 0:00:43.98\n",
      "Accuracy: 0.7576\n",
      "F1 Score: 0.756475387559863\n",
      "Layer One: 256\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.80      1000\n",
      "           1       0.85      0.85      0.85      1000\n",
      "           2       0.69      0.66      0.67      1000\n",
      "           3       0.60      0.56      0.58      1000\n",
      "           4       0.75      0.68      0.71      1000\n",
      "           5       0.66      0.67      0.67      1000\n",
      "           6       0.76      0.87      0.81      1000\n",
      "           7       0.79      0.81      0.80      1000\n",
      "           8       0.92      0.79      0.85      1000\n",
      "           9       0.83      0.82      0.83      1000\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:adam\n",
      "f1 score:0.756475387559863\n",
      "layer one neurons: 256\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:39.92\n",
      "Accuracy: 0.5122\n",
      "F1 Score: 0.5023591124600004\n",
      "Layer One: 32\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.57      1000\n",
      "           1       0.57      0.67      0.61      1000\n",
      "           2       0.45      0.27      0.34      1000\n",
      "           3       0.39      0.28      0.32      1000\n",
      "           4       0.48      0.31      0.38      1000\n",
      "           5       0.41      0.55      0.47      1000\n",
      "           6       0.56      0.63      0.59      1000\n",
      "           7       0.49      0.64      0.56      1000\n",
      "           8       0.65      0.62      0.63      1000\n",
      "           9       0.51      0.61      0.56      1000\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.51      0.51      0.50     10000\n",
      "weighted avg       0.51      0.51      0.50     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5023591124600004\n",
      "layer one neurons: 32\n",
      "layer two neurons: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:40.73\n",
      "Accuracy: 0.5328\n",
      "F1 Score: 0.5235880274781259\n",
      "Layer One: 32\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58      1000\n",
      "           1       0.60      0.71      0.65      1000\n",
      "           2       0.47      0.35      0.40      1000\n",
      "           3       0.40      0.33      0.36      1000\n",
      "           4       0.47      0.37      0.42      1000\n",
      "           5       0.50      0.40      0.44      1000\n",
      "           6       0.53      0.67      0.59      1000\n",
      "           7       0.59      0.57      0.58      1000\n",
      "           8       0.57      0.75      0.65      1000\n",
      "           9       0.54      0.59      0.56      1000\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.52      0.53      0.52     10000\n",
      "weighted avg       0.52      0.53      0.52     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5235880274781259\n",
      "layer one neurons: 32\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:00:40.80\n",
      "Accuracy: 0.5315\n",
      "F1 Score: 0.5267337282710173\n",
      "Layer One: 32\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.53      0.57      1000\n",
      "           1       0.68      0.58      0.62      1000\n",
      "           2       0.38      0.48      0.43      1000\n",
      "           3       0.43      0.30      0.35      1000\n",
      "           4       0.47      0.41      0.44      1000\n",
      "           5       0.53      0.40      0.46      1000\n",
      "           6       0.53      0.68      0.60      1000\n",
      "           7       0.58      0.61      0.59      1000\n",
      "           8       0.55      0.75      0.63      1000\n",
      "           9       0.56      0.58      0.57      1000\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.53      0.53      0.53     10000\n",
      "weighted avg       0.53      0.53      0.53     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5267337282710173\n",
      "layer one neurons: 32\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:00:42.18\n",
      "Accuracy: 0.5551\n",
      "F1 Score: 0.5518132072453017\n",
      "Layer One: 32\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64      1000\n",
      "           1       0.65      0.68      0.67      1000\n",
      "           2       0.44      0.42      0.43      1000\n",
      "           3       0.42      0.33      0.37      1000\n",
      "           4       0.48      0.45      0.47      1000\n",
      "           5       0.47      0.47      0.47      1000\n",
      "           6       0.60      0.63      0.62      1000\n",
      "           7       0.52      0.69      0.59      1000\n",
      "           8       0.69      0.67      0.68      1000\n",
      "           9       0.60      0.59      0.60      1000\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.55      0.56      0.55     10000\n",
      "weighted avg       0.55      0.56      0.55     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5518132072453017\n",
      "layer one neurons: 32\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:42.42\n",
      "Accuracy: 0.5282\n",
      "F1 Score: 0.5193443951622503\n",
      "Layer One: 64\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.60      1000\n",
      "           1       0.61      0.65      0.63      1000\n",
      "           2       0.46      0.29      0.36      1000\n",
      "           3       0.41      0.31      0.35      1000\n",
      "           4       0.45      0.43      0.44      1000\n",
      "           5       0.49      0.40      0.44      1000\n",
      "           6       0.50      0.72      0.59      1000\n",
      "           7       0.52      0.65      0.58      1000\n",
      "           8       0.65      0.65      0.65      1000\n",
      "           9       0.54      0.58      0.56      1000\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.52      0.53      0.52     10000\n",
      "weighted avg       0.52      0.53      0.52     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5193443951622503\n",
      "layer one neurons: 64\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:42.24\n",
      "Accuracy: 0.5416\n",
      "F1 Score: 0.5353234989593064\n",
      "Layer One: 64\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59      1000\n",
      "           1       0.64      0.67      0.65      1000\n",
      "           2       0.44      0.38      0.41      1000\n",
      "           3       0.41      0.33      0.36      1000\n",
      "           4       0.50      0.39      0.44      1000\n",
      "           5       0.48      0.45      0.46      1000\n",
      "           6       0.51      0.72      0.60      1000\n",
      "           7       0.55      0.64      0.59      1000\n",
      "           8       0.63      0.70      0.67      1000\n",
      "           9       0.56      0.59      0.58      1000\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.54      0.54      0.54     10000\n",
      "weighted avg       0.54      0.54      0.54     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5353234989593064\n",
      "layer one neurons: 64\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:00:43.35\n",
      "Accuracy: 0.5525\n",
      "F1 Score: 0.5473494936890615\n",
      "Layer One: 64\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61      1000\n",
      "           1       0.67      0.66      0.67      1000\n",
      "           2       0.48      0.34      0.40      1000\n",
      "           3       0.39      0.39      0.39      1000\n",
      "           4       0.49      0.44      0.46      1000\n",
      "           5       0.50      0.41      0.45      1000\n",
      "           6       0.53      0.73      0.61      1000\n",
      "           7       0.54      0.69      0.60      1000\n",
      "           8       0.68      0.67      0.67      1000\n",
      "           9       0.58      0.64      0.61      1000\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.55      0.55      0.55     10000\n",
      "weighted avg       0.55      0.55      0.55     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5473494936890615\n",
      "layer one neurons: 64\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:00:44.76\n",
      "Accuracy: 0.5449\n",
      "F1 Score: 0.5350892442044322\n",
      "Layer One: 64\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.62      1000\n",
      "           1       0.51      0.85      0.63      1000\n",
      "           2       0.45      0.43      0.44      1000\n",
      "           3       0.42      0.36      0.39      1000\n",
      "           4       0.51      0.38      0.44      1000\n",
      "           5       0.59      0.31      0.41      1000\n",
      "           6       0.50      0.77      0.60      1000\n",
      "           7       0.68      0.56      0.61      1000\n",
      "           8       0.66      0.69      0.68      1000\n",
      "           9       0.55      0.53      0.53      1000\n",
      "\n",
      "    accuracy                           0.54     10000\n",
      "   macro avg       0.55      0.54      0.54     10000\n",
      "weighted avg       0.55      0.54      0.54     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5350892442044322\n",
      "layer one neurons: 64\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:46.74\n",
      "Accuracy: 0.5109\n",
      "F1 Score: 0.49762515146408987\n",
      "Layer One: 128\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56      1000\n",
      "           1       0.55      0.69      0.61      1000\n",
      "           2       0.52      0.26      0.34      1000\n",
      "           3       0.38      0.28      0.32      1000\n",
      "           4       0.55      0.28      0.37      1000\n",
      "           5       0.42      0.50      0.46      1000\n",
      "           6       0.51      0.71      0.59      1000\n",
      "           7       0.48      0.64      0.55      1000\n",
      "           8       0.61      0.63      0.62      1000\n",
      "           9       0.49      0.60      0.54      1000\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.51      0.51      0.50     10000\n",
      "weighted avg       0.51      0.51      0.50     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.49762515146408987\n",
      "layer one neurons: 128\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:47.68\n",
      "Accuracy: 0.5331\n",
      "F1 Score: 0.5213516977594764\n",
      "Layer One: 128\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.52      0.57      1000\n",
      "           1       0.61      0.71      0.66      1000\n",
      "           2       0.58      0.23      0.32      1000\n",
      "           3       0.37      0.43      0.40      1000\n",
      "           4       0.54      0.31      0.39      1000\n",
      "           5       0.48      0.46      0.47      1000\n",
      "           6       0.51      0.71      0.59      1000\n",
      "           7       0.59      0.58      0.59      1000\n",
      "           8       0.61      0.69      0.65      1000\n",
      "           9       0.49      0.70      0.57      1000\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.54      0.53      0.52     10000\n",
      "weighted avg       0.54      0.53      0.52     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5213516977594764\n",
      "layer one neurons: 128\n",
      "layer two neurons: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:47.25\n",
      "Accuracy: 0.5346\n",
      "F1 Score: 0.5345460669018822\n",
      "Layer One: 128\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.59      1000\n",
      "           1       0.76      0.53      0.62      1000\n",
      "           2       0.36      0.55      0.43      1000\n",
      "           3       0.39      0.38      0.38      1000\n",
      "           4       0.54      0.32      0.40      1000\n",
      "           5       0.44      0.47      0.45      1000\n",
      "           6       0.64      0.57      0.60      1000\n",
      "           7       0.65      0.56      0.60      1000\n",
      "           8       0.57      0.74      0.65      1000\n",
      "           9       0.59      0.64      0.61      1000\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.55      0.53      0.53     10000\n",
      "weighted avg       0.55      0.53      0.53     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5345460669018822\n",
      "layer one neurons: 128\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:00:49.79\n",
      "Accuracy: 0.5652\n",
      "F1 Score: 0.5592412965149486\n",
      "Layer One: 128\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64      1000\n",
      "           1       0.67      0.66      0.67      1000\n",
      "           2       0.41      0.51      0.45      1000\n",
      "           3       0.47      0.26      0.34      1000\n",
      "           4       0.48      0.47      0.47      1000\n",
      "           5       0.51      0.45      0.48      1000\n",
      "           6       0.58      0.72      0.65      1000\n",
      "           7       0.63      0.63      0.63      1000\n",
      "           8       0.63      0.73      0.68      1000\n",
      "           9       0.63      0.56      0.60      1000\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.56      0.57      0.56     10000\n",
      "weighted avg       0.56      0.57      0.56     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5592412965149486\n",
      "layer one neurons: 128\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:53.67\n",
      "Accuracy: 0.5279\n",
      "F1 Score: 0.5241688242384028\n",
      "Layer One: 256\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.66      0.60      1000\n",
      "           1       0.67      0.61      0.64      1000\n",
      "           2       0.45      0.33      0.38      1000\n",
      "           3       0.39      0.31      0.35      1000\n",
      "           4       0.49      0.44      0.46      1000\n",
      "           5       0.41      0.56      0.47      1000\n",
      "           6       0.55      0.60      0.57      1000\n",
      "           7       0.52      0.65      0.58      1000\n",
      "           8       0.63      0.62      0.62      1000\n",
      "           9       0.63      0.52      0.57      1000\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.53      0.53      0.52     10000\n",
      "weighted avg       0.53      0.53      0.52     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5241688242384028\n",
      "layer one neurons: 256\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:56.01\n",
      "Accuracy: 0.5319\n",
      "F1 Score: 0.5284948415416272\n",
      "Layer One: 256\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.60      1000\n",
      "           1       0.64      0.66      0.65      1000\n",
      "           2       0.46      0.30      0.37      1000\n",
      "           3       0.36      0.42      0.39      1000\n",
      "           4       0.51      0.35      0.41      1000\n",
      "           5       0.42      0.52      0.46      1000\n",
      "           6       0.58      0.63      0.60      1000\n",
      "           7       0.54      0.65      0.59      1000\n",
      "           8       0.69      0.56      0.62      1000\n",
      "           9       0.56      0.61      0.59      1000\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.54      0.53      0.53     10000\n",
      "weighted avg       0.54      0.53      0.53     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5284948415416272\n",
      "layer one neurons: 256\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:00:55.47\n",
      "Accuracy: 0.5495\n",
      "F1 Score: 0.5439792752004307\n",
      "Layer One: 256\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60      1000\n",
      "           1       0.63      0.69      0.66      1000\n",
      "           2       0.47      0.36      0.41      1000\n",
      "           3       0.38      0.41      0.40      1000\n",
      "           4       0.49      0.47      0.48      1000\n",
      "           5       0.54      0.38      0.44      1000\n",
      "           6       0.57      0.69      0.62      1000\n",
      "           7       0.64      0.58      0.61      1000\n",
      "           8       0.55      0.79      0.65      1000\n",
      "           9       0.58      0.57      0.58      1000\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.55      0.55      0.54     10000\n",
      "weighted avg       0.55      0.55      0.54     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5439792752004307\n",
      "layer one neurons: 256\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:00:58.03\n",
      "Accuracy: 0.5532\n",
      "F1 Score: 0.5536382609901356\n",
      "Layer One: 256\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.52      0.60      1000\n",
      "           1       0.78      0.53      0.63      1000\n",
      "           2       0.43      0.46      0.44      1000\n",
      "           3       0.39      0.39      0.39      1000\n",
      "           4       0.59      0.37      0.46      1000\n",
      "           5       0.42      0.56      0.48      1000\n",
      "           6       0.55      0.71      0.62      1000\n",
      "           7       0.55      0.69      0.61      1000\n",
      "           8       0.72      0.65      0.68      1000\n",
      "           9       0.59      0.65      0.62      1000\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.57      0.55      0.55     10000\n",
      "weighted avg       0.57      0.55      0.55     10000\n",
      "\n",
      "activation:relu\n",
      "optimizer:sgd\n",
      "f1 score:0.5536382609901356\n",
      "layer one neurons: 256\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:42.01\n",
      "Accuracy: 0.5612\n",
      "F1 Score: 0.5599256642637377\n",
      "Layer One: 32\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62      1000\n",
      "           1       0.69      0.62      0.65      1000\n",
      "           2       0.43      0.52      0.47      1000\n",
      "           3       0.44      0.33      0.38      1000\n",
      "           4       0.51      0.47      0.49      1000\n",
      "           5       0.46      0.52      0.49      1000\n",
      "           6       0.60      0.63      0.62      1000\n",
      "           7       0.65      0.57      0.61      1000\n",
      "           8       0.67      0.69      0.68      1000\n",
      "           9       0.56      0.65      0.60      1000\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.56      0.56      0.56     10000\n",
      "weighted avg       0.56      0.56      0.56     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.5599256642637377\n",
      "layer one neurons: 32\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:44.33\n",
      "Accuracy: 0.5992\n",
      "F1 Score: 0.5970433880706926\n",
      "Layer One: 32\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65      1000\n",
      "           1       0.62      0.77      0.68      1000\n",
      "           2       0.49      0.53      0.51      1000\n",
      "           3       0.44      0.45      0.45      1000\n",
      "           4       0.56      0.56      0.56      1000\n",
      "           5       0.57      0.42      0.48      1000\n",
      "           6       0.64      0.72      0.67      1000\n",
      "           7       0.72      0.57      0.64      1000\n",
      "           8       0.70      0.72      0.71      1000\n",
      "           9       0.61      0.61      0.61      1000\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.60      0.60      0.60     10000\n",
      "weighted avg       0.60      0.60      0.60     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.5970433880706926\n",
      "layer one neurons: 32\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:00:45.18\n",
      "Accuracy: 0.6284\n",
      "F1 Score: 0.6248708141667842\n",
      "Layer One: 32\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70      1000\n",
      "           1       0.68      0.76      0.72      1000\n",
      "           2       0.59      0.48      0.53      1000\n",
      "           3       0.48      0.45      0.46      1000\n",
      "           4       0.59      0.51      0.55      1000\n",
      "           5       0.56      0.51      0.53      1000\n",
      "           6       0.55      0.80      0.65      1000\n",
      "           7       0.68      0.71      0.69      1000\n",
      "           8       0.74      0.74      0.74      1000\n",
      "           9       0.70      0.64      0.67      1000\n",
      "\n",
      "    accuracy                           0.63     10000\n",
      "   macro avg       0.63      0.63      0.62     10000\n",
      "weighted avg       0.63      0.63      0.62     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6248708141667842\n",
      "layer one neurons: 32\n",
      "layer two neurons: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:46.33\n",
      "Accuracy: 0.6477\n",
      "F1 Score: 0.6475295974939415\n",
      "Layer One: 32\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70      1000\n",
      "           1       0.70      0.79      0.74      1000\n",
      "           2       0.58      0.54      0.55      1000\n",
      "           3       0.48      0.52      0.50      1000\n",
      "           4       0.63      0.56      0.59      1000\n",
      "           5       0.52      0.59      0.56      1000\n",
      "           6       0.79      0.62      0.69      1000\n",
      "           7       0.67      0.76      0.71      1000\n",
      "           8       0.70      0.81      0.75      1000\n",
      "           9       0.72      0.64      0.68      1000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.65      0.65      0.65     10000\n",
      "weighted avg       0.65      0.65      0.65     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6475295974939415\n",
      "layer one neurons: 32\n",
      "layer two neurons: 128\n",
      "Epoch 00006: early stopping\n",
      "Elapsed time: 0:00:20.18\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 64\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.10      1.00      0.18      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 64\n",
      "layer two neurons: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:46.77\n",
      "Accuracy: 0.6252\n",
      "F1 Score: 0.6213925478083261\n",
      "Layer One: 64\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69      1000\n",
      "           1       0.73      0.71      0.72      1000\n",
      "           2       0.64      0.44      0.52      1000\n",
      "           3       0.47      0.46      0.46      1000\n",
      "           4       0.59      0.53      0.56      1000\n",
      "           5       0.53      0.51      0.52      1000\n",
      "           6       0.61      0.78      0.68      1000\n",
      "           7       0.63      0.72      0.68      1000\n",
      "           8       0.69      0.76      0.73      1000\n",
      "           9       0.67      0.65      0.66      1000\n",
      "\n",
      "    accuracy                           0.63     10000\n",
      "   macro avg       0.62      0.63      0.62     10000\n",
      "weighted avg       0.62      0.63      0.62     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6213925478083261\n",
      "layer one neurons: 64\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:00:47.14\n",
      "Accuracy: 0.6379\n",
      "F1 Score: 0.6409694197441472\n",
      "Layer One: 64\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71      1000\n",
      "           1       0.81      0.64      0.71      1000\n",
      "           2       0.57      0.48      0.52      1000\n",
      "           3       0.47      0.47      0.47      1000\n",
      "           4       0.54      0.64      0.59      1000\n",
      "           5       0.47      0.68      0.56      1000\n",
      "           6       0.77      0.66      0.71      1000\n",
      "           7       0.77      0.64      0.70      1000\n",
      "           8       0.79      0.71      0.75      1000\n",
      "           9       0.66      0.74      0.70      1000\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.65      0.64      0.64     10000\n",
      "weighted avg       0.65      0.64      0.64     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6409694197441472\n",
      "layer one neurons: 64\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:00:50.17\n",
      "Accuracy: 0.6637\n",
      "F1 Score: 0.6652846450672185\n",
      "Layer One: 64\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72      1000\n",
      "           1       0.82      0.72      0.77      1000\n",
      "           2       0.58      0.55      0.56      1000\n",
      "           3       0.47      0.57      0.51      1000\n",
      "           4       0.61      0.60      0.60      1000\n",
      "           5       0.58      0.55      0.57      1000\n",
      "           6       0.80      0.64      0.71      1000\n",
      "           7       0.67      0.78      0.72      1000\n",
      "           8       0.77      0.79      0.78      1000\n",
      "           9       0.69      0.72      0.71      1000\n",
      "\n",
      "    accuracy                           0.66     10000\n",
      "   macro avg       0.67      0.66      0.67     10000\n",
      "weighted avg       0.67      0.66      0.67     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6652846450672185\n",
      "layer one neurons: 64\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:50.45\n",
      "Accuracy: 0.5869\n",
      "F1 Score: 0.5813757149816595\n",
      "Layer One: 128\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61      1000\n",
      "           1       0.65      0.77      0.70      1000\n",
      "           2       0.50      0.44      0.47      1000\n",
      "           3       0.45      0.38      0.41      1000\n",
      "           4       0.52      0.53      0.52      1000\n",
      "           5       0.53      0.44      0.48      1000\n",
      "           6       0.59      0.72      0.65      1000\n",
      "           7       0.73      0.59      0.65      1000\n",
      "           8       0.60      0.81      0.69      1000\n",
      "           9       0.61      0.64      0.62      1000\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.59      0.59      0.58     10000\n",
      "weighted avg       0.59      0.59      0.58     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.5813757149816595\n",
      "layer one neurons: 128\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:52.09\n",
      "Accuracy: 0.6447\n",
      "F1 Score: 0.6440819352081535\n",
      "Layer One: 128\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69      1000\n",
      "           1       0.76      0.71      0.73      1000\n",
      "           2       0.59      0.49      0.54      1000\n",
      "           3       0.47      0.50      0.49      1000\n",
      "           4       0.62      0.57      0.60      1000\n",
      "           5       0.55      0.54      0.54      1000\n",
      "           6       0.68      0.72      0.70      1000\n",
      "           7       0.72      0.71      0.72      1000\n",
      "           8       0.79      0.75      0.77      1000\n",
      "           9       0.63      0.73      0.68      1000\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.65      0.64      0.64     10000\n",
      "weighted avg       0.65      0.64      0.64     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6440819352081535\n",
      "layer one neurons: 128\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:00:52.13\n",
      "Accuracy: 0.6517\n",
      "F1 Score: 0.6523438852616469\n",
      "Layer One: 128\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71      1000\n",
      "           1       0.69      0.80      0.74      1000\n",
      "           2       0.58      0.55      0.57      1000\n",
      "           3       0.46      0.53      0.50      1000\n",
      "           4       0.63      0.58      0.60      1000\n",
      "           5       0.55      0.56      0.56      1000\n",
      "           6       0.80      0.64      0.71      1000\n",
      "           7       0.69      0.72      0.71      1000\n",
      "           8       0.77      0.73      0.75      1000\n",
      "           9       0.71      0.65      0.68      1000\n",
      "\n",
      "    accuracy                           0.65     10000\n",
      "   macro avg       0.66      0.65      0.65     10000\n",
      "weighted avg       0.66      0.65      0.65     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6523438852616469\n",
      "layer one neurons: 128\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:00:55.21\n",
      "Accuracy: 0.6813\n",
      "F1 Score: 0.6814210619885623\n",
      "Layer One: 128\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73      1000\n",
      "           1       0.80      0.78      0.79      1000\n",
      "           2       0.56      0.61      0.59      1000\n",
      "           3       0.52      0.48      0.50      1000\n",
      "           4       0.64      0.61      0.62      1000\n",
      "           5       0.56      0.62      0.59      1000\n",
      "           6       0.73      0.72      0.73      1000\n",
      "           7       0.76      0.73      0.74      1000\n",
      "           8       0.76      0.81      0.78      1000\n",
      "           9       0.77      0.71      0.74      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.68      0.68      0.68     10000\n",
      "weighted avg       0.68      0.68      0.68     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6814210619885623\n",
      "layer one neurons: 128\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:58.68\n",
      "Accuracy: 0.5878\n",
      "F1 Score: 0.5811803697261104\n",
      "Layer One: 256\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64      1000\n",
      "           1       0.63      0.77      0.69      1000\n",
      "           2       0.51      0.41      0.46      1000\n",
      "           3       0.44      0.37      0.40      1000\n",
      "           4       0.59      0.46      0.52      1000\n",
      "           5       0.52      0.50      0.51      1000\n",
      "           6       0.56      0.75      0.64      1000\n",
      "           7       0.64      0.67      0.66      1000\n",
      "           8       0.63      0.76      0.69      1000\n",
      "           9       0.64      0.56      0.60      1000\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.58      0.59      0.58     10000\n",
      "weighted avg       0.58      0.59      0.58     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.5811803697261104\n",
      "layer one neurons: 256\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:01:00.42\n",
      "Accuracy: 0.6168\n",
      "F1 Score: 0.6118022591070152\n",
      "Layer One: 256\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.68      1000\n",
      "           1       0.75      0.67      0.71      1000\n",
      "           2       0.50      0.56      0.53      1000\n",
      "           3       0.51      0.28      0.36      1000\n",
      "           4       0.60      0.52      0.56      1000\n",
      "           5       0.52      0.56      0.54      1000\n",
      "           6       0.53      0.82      0.65      1000\n",
      "           7       0.71      0.66      0.69      1000\n",
      "           8       0.80      0.70      0.75      1000\n",
      "           9       0.64      0.70      0.67      1000\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.62      0.62      0.61     10000\n",
      "weighted avg       0.62      0.62      0.61     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6118022591070152\n",
      "layer one neurons: 256\n",
      "layer two neurons: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:01:00.61\n",
      "Accuracy: 0.6729\n",
      "F1 Score: 0.6743842989143025\n",
      "Layer One: 256\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73      1000\n",
      "           1       0.76      0.78      0.77      1000\n",
      "           2       0.64      0.50      0.56      1000\n",
      "           3       0.46      0.58      0.51      1000\n",
      "           4       0.67      0.59      0.63      1000\n",
      "           5       0.55      0.62      0.58      1000\n",
      "           6       0.73      0.71      0.72      1000\n",
      "           7       0.75      0.73      0.74      1000\n",
      "           8       0.81      0.74      0.77      1000\n",
      "           9       0.75      0.70      0.72      1000\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.68      0.67      0.67     10000\n",
      "weighted avg       0.68      0.67      0.67     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6743842989143025\n",
      "layer one neurons: 256\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:01:04.15\n",
      "Accuracy: 0.6771\n",
      "F1 Score: 0.6738787505363425\n",
      "Layer One: 256\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72      1000\n",
      "           1       0.79      0.76      0.77      1000\n",
      "           2       0.62      0.53      0.57      1000\n",
      "           3       0.56      0.44      0.50      1000\n",
      "           4       0.63      0.63      0.63      1000\n",
      "           5       0.58      0.60      0.59      1000\n",
      "           6       0.65      0.80      0.72      1000\n",
      "           7       0.76      0.70      0.73      1000\n",
      "           8       0.78      0.80      0.79      1000\n",
      "           9       0.70      0.74      0.72      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.68      0.68      0.67     10000\n",
      "weighted avg       0.68      0.68      0.67     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:adam\n",
      "f1 score:0.6738787505363425\n",
      "layer one neurons: 256\n",
      "layer two neurons: 128\n",
      "Epoch 00008: early stopping\n",
      "Elapsed time: 0:00:26.51\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 32\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.10      1.00      0.18      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 32\n",
      "layer two neurons: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "Elapsed time: 0:00:20.63\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.018183471224656786\n",
      "Layer One: 32\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.10      1.00      0.18      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.018183471224656786\n",
      "layer one neurons: 32\n",
      "layer two neurons: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "Elapsed time: 0:00:26.49\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 32\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.10      1.00      0.18      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 32\n",
      "layer two neurons: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "Elapsed time: 0:00:29.86\n",
      "Accuracy: 0.1002\n",
      "F1 Score: 0.01899209675604413\n",
      "Layer One: 32\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.10      1.00      0.18      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.08      0.00      0.01      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.02      0.10      0.02     10000\n",
      "weighted avg       0.02      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01899209675604413\n",
      "layer one neurons: 32\n",
      "layer two neurons: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "Elapsed time: 0:00:30.57\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 64\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.10      1.00      0.18      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 64\n",
      "layer two neurons: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: early stopping\n",
      "Elapsed time: 0:00:33.04\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 64\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.10      1.00      0.18      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 64\n",
      "layer two neurons: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "Elapsed time: 0:00:21.75\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 64\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.10      1.00      0.18      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 64\n",
      "layer two neurons: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "Elapsed time: 0:00:28.72\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 64\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.10      1.00      0.18      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 64\n",
      "layer two neurons: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: early stopping\n",
      "Elapsed time: 0:00:38.66\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 128\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.10      1.00      0.18      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 128\n",
      "layer two neurons: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "Elapsed time: 0:00:23.00\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 128\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.10      1.00      0.18      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 128\n",
      "layer two neurons: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n",
      "Elapsed time: 0:00:33.39\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 128\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.10      1.00      0.18      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 128\n",
      "layer two neurons: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: early stopping\n",
      "Elapsed time: 0:00:27.59\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 128\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.10      1.00      0.18      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 128\n",
      "layer two neurons: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "Elapsed time: 0:00:33.20\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 256\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.10      1.00      0.18      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 256\n",
      "layer two neurons: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "Elapsed time: 0:00:26.66\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 256\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.10      1.00      0.18      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 256\n",
      "layer two neurons: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: early stopping\n",
      "Elapsed time: 0:00:30.74\n",
      "Accuracy: 0.0994\n",
      "F1 Score: 0.025830416643389822\n",
      "Layer One: 256\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.00      0.00      0.00      1000\n",
      "           3       0.10      0.94      0.18      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.14      0.06      0.08      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.02      0.10      0.03     10000\n",
      "weighted avg       0.02      0.10      0.03     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.025830416643389822\n",
      "layer one neurons: 256\n",
      "layer two neurons: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "Elapsed time: 0:00:35.73\n",
      "Accuracy: 0.1\n",
      "F1 Score: 0.01818181818181818\n",
      "Layer One: 256\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       0.00      0.00      0.00      1000\n",
      "           2       0.10      1.00      0.18      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.00      0.00      0.00      1000\n",
      "           6       0.00      0.00      0.00      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.00      0.00      0.00      1000\n",
      "           9       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "activation:sigmoid\n",
      "optimizer:sgd\n",
      "f1 score:0.01818181818181818\n",
      "layer one neurons: 256\n",
      "layer two neurons: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19165\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:48.27\n",
      "Accuracy: 0.6774\n",
      "F1 Score: 0.6765769238748255\n",
      "Layer One: 32\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      1000\n",
      "           1       0.78      0.82      0.80      1000\n",
      "           2       0.54      0.55      0.55      1000\n",
      "           3       0.52      0.49      0.51      1000\n",
      "           4       0.62      0.62      0.62      1000\n",
      "           5       0.59      0.55      0.57      1000\n",
      "           6       0.66      0.84      0.74      1000\n",
      "           7       0.77      0.70      0.73      1000\n",
      "           8       0.84      0.72      0.77      1000\n",
      "           9       0.77      0.76      0.77      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.68      0.68      0.68     10000\n",
      "weighted avg       0.68      0.68      0.68     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6765769238748255\n",
      "layer one neurons: 32\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:49.25\n",
      "Accuracy: 0.6847\n",
      "F1 Score: 0.685361449575843\n",
      "Layer One: 32\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.70      1000\n",
      "           1       0.80      0.80      0.80      1000\n",
      "           2       0.52      0.68      0.59      1000\n",
      "           3       0.49      0.54      0.52      1000\n",
      "           4       0.67      0.57      0.62      1000\n",
      "           5       0.65      0.53      0.58      1000\n",
      "           6       0.83      0.66      0.74      1000\n",
      "           7       0.73      0.75      0.74      1000\n",
      "           8       0.75      0.85      0.79      1000\n",
      "           9       0.79      0.77      0.78      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.69      0.68      0.69     10000\n",
      "weighted avg       0.69      0.68      0.69     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.685361449575843\n",
      "layer one neurons: 32\n",
      "layer two neurons: 32\n",
      "Epoch 00013: early stopping\n",
      "Elapsed time: 0:00:44.08\n",
      "Accuracy: 0.6905\n",
      "F1 Score: 0.687070847137844\n",
      "Layer One: 32\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      1000\n",
      "           1       0.82      0.77      0.80      1000\n",
      "           2       0.61      0.54      0.57      1000\n",
      "           3       0.53      0.49      0.51      1000\n",
      "           4       0.59      0.71      0.65      1000\n",
      "           5       0.67      0.49      0.57      1000\n",
      "           6       0.73      0.79      0.76      1000\n",
      "           7       0.69      0.77      0.73      1000\n",
      "           8       0.75      0.87      0.81      1000\n",
      "           9       0.81      0.73      0.77      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.687070847137844\n",
      "layer one neurons: 32\n",
      "layer two neurons: 64\n",
      "Epoch 00010: early stopping\n",
      "Elapsed time: 0:00:36.38\n",
      "Accuracy: 0.6757\n",
      "F1 Score: 0.6773997472240578\n",
      "Layer One: 32\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      1000\n",
      "           1       0.81      0.80      0.80      1000\n",
      "           2       0.53      0.56      0.55      1000\n",
      "           3       0.48      0.55      0.51      1000\n",
      "           4       0.57      0.61      0.59      1000\n",
      "           5       0.61      0.56      0.59      1000\n",
      "           6       0.73      0.79      0.76      1000\n",
      "           7       0.82      0.61      0.70      1000\n",
      "           8       0.80      0.80      0.80      1000\n",
      "           9       0.79      0.74      0.76      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.68      0.68      0.68     10000\n",
      "weighted avg       0.68      0.68      0.68     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6773997472240578\n",
      "layer one neurons: 32\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:51.38\n",
      "Accuracy: 0.6949\n",
      "F1 Score: 0.6945687094431208\n",
      "Layer One: 64\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73      1000\n",
      "           1       0.77      0.84      0.80      1000\n",
      "           2       0.58      0.58      0.58      1000\n",
      "           3       0.52      0.52      0.52      1000\n",
      "           4       0.68      0.64      0.65      1000\n",
      "           5       0.60      0.57      0.58      1000\n",
      "           6       0.77      0.77      0.77      1000\n",
      "           7       0.75      0.71      0.73      1000\n",
      "           8       0.84      0.76      0.80      1000\n",
      "           9       0.79      0.76      0.77      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.70      0.69      0.69     10000\n",
      "weighted avg       0.70      0.69      0.69     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6945687094431208\n",
      "layer one neurons: 64\n",
      "layer two neurons: 16\n",
      "Epoch 00015: early stopping\n",
      "Elapsed time: 0:00:51.96\n",
      "Accuracy: 0.6959\n",
      "F1 Score: 0.695673282651995\n",
      "Layer One: 64\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.67      0.72      1000\n",
      "           1       0.84      0.76      0.80      1000\n",
      "           2       0.61      0.58      0.59      1000\n",
      "           3       0.50      0.53      0.52      1000\n",
      "           4       0.58      0.75      0.65      1000\n",
      "           5       0.63      0.53      0.57      1000\n",
      "           6       0.79      0.74      0.76      1000\n",
      "           7       0.74      0.73      0.73      1000\n",
      "           8       0.78      0.84      0.81      1000\n",
      "           9       0.76      0.83      0.79      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.70     10000\n",
      "weighted avg       0.70      0.70      0.70     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.695673282651995\n",
      "layer one neurons: 64\n",
      "layer two neurons: 32\n",
      "Epoch 00012: early stopping\n",
      "Elapsed time: 0:00:43.48\n",
      "Accuracy: 0.6983\n",
      "F1 Score: 0.6980511207622433\n",
      "Layer One: 64\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.79      0.72      1000\n",
      "           1       0.80      0.80      0.80      1000\n",
      "           2       0.53      0.66      0.59      1000\n",
      "           3       0.56      0.52      0.54      1000\n",
      "           4       0.72      0.57      0.64      1000\n",
      "           5       0.62      0.57      0.59      1000\n",
      "           6       0.79      0.74      0.76      1000\n",
      "           7       0.73      0.76      0.75      1000\n",
      "           8       0.79      0.82      0.81      1000\n",
      "           9       0.81      0.75      0.78      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.70     10000\n",
      "weighted avg       0.70      0.70      0.70     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6980511207622433\n",
      "layer one neurons: 64\n",
      "layer two neurons: 64\n",
      "Epoch 00011: early stopping\n",
      "Elapsed time: 0:00:41.63\n",
      "Accuracy: 0.6884\n",
      "F1 Score: 0.6833634688195084\n",
      "Layer One: 64\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75      1000\n",
      "           1       0.78      0.81      0.80      1000\n",
      "           2       0.60      0.54      0.57      1000\n",
      "           3       0.58      0.40      0.47      1000\n",
      "           4       0.60      0.66      0.63      1000\n",
      "           5       0.61      0.56      0.58      1000\n",
      "           6       0.82      0.72      0.76      1000\n",
      "           7       0.64      0.79      0.71      1000\n",
      "           8       0.78      0.82      0.80      1000\n",
      "           9       0.72      0.81      0.76      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.68     10000\n",
      "weighted avg       0.69      0.69      0.68     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6833634688195084\n",
      "layer one neurons: 64\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:55.82\n",
      "Accuracy: 0.6908\n",
      "F1 Score: 0.6906833709454263\n",
      "Layer One: 128\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      1000\n",
      "           1       0.83      0.77      0.80      1000\n",
      "           2       0.55      0.63      0.59      1000\n",
      "           3       0.51      0.49      0.50      1000\n",
      "           4       0.60      0.70      0.65      1000\n",
      "           5       0.64      0.51      0.56      1000\n",
      "           6       0.73      0.78      0.76      1000\n",
      "           7       0.78      0.71      0.74      1000\n",
      "           8       0.82      0.79      0.81      1000\n",
      "           9       0.78      0.78      0.78      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6906833709454263\n",
      "layer one neurons: 128\n",
      "layer two neurons: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: early stopping\n",
      "Elapsed time: 0:00:53.13\n",
      "Accuracy: 0.698\n",
      "F1 Score: 0.6954070512845502\n",
      "Layer One: 128\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72      1000\n",
      "           1       0.84      0.80      0.82      1000\n",
      "           2       0.67      0.52      0.58      1000\n",
      "           3       0.53      0.53      0.53      1000\n",
      "           4       0.70      0.57      0.63      1000\n",
      "           5       0.58      0.63      0.61      1000\n",
      "           6       0.68      0.82      0.74      1000\n",
      "           7       0.74      0.76      0.75      1000\n",
      "           8       0.75      0.87      0.81      1000\n",
      "           9       0.80      0.76      0.78      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.70     10000\n",
      "weighted avg       0.70      0.70      0.70     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6954070512845502\n",
      "layer one neurons: 128\n",
      "layer two neurons: 32\n",
      "Epoch 00011: early stopping\n",
      "Elapsed time: 0:00:43.68\n",
      "Accuracy: 0.6996\n",
      "F1 Score: 0.6994606916660454\n",
      "Layer One: 128\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71      1000\n",
      "           1       0.79      0.84      0.82      1000\n",
      "           2       0.59      0.60      0.60      1000\n",
      "           3       0.52      0.54      0.53      1000\n",
      "           4       0.61      0.69      0.65      1000\n",
      "           5       0.65      0.58      0.61      1000\n",
      "           6       0.77      0.74      0.75      1000\n",
      "           7       0.74      0.76      0.75      1000\n",
      "           8       0.75      0.85      0.80      1000\n",
      "           9       0.84      0.73      0.78      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.70     10000\n",
      "weighted avg       0.70      0.70      0.70     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6994606916660454\n",
      "layer one neurons: 128\n",
      "layer two neurons: 64\n",
      "Epoch 00010: early stopping\n",
      "Elapsed time: 0:00:42.40\n",
      "Accuracy: 0.7\n",
      "F1 Score: 0.7009232839220809\n",
      "Layer One: 128\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1000\n",
      "           1       0.86      0.78      0.82      1000\n",
      "           2       0.62      0.56      0.59      1000\n",
      "           3       0.57      0.41      0.47      1000\n",
      "           4       0.65      0.69      0.67      1000\n",
      "           5       0.48      0.76      0.59      1000\n",
      "           6       0.72      0.81      0.76      1000\n",
      "           7       0.83      0.67      0.74      1000\n",
      "           8       0.83      0.81      0.82      1000\n",
      "           9       0.83      0.76      0.79      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.7009232839220809\n",
      "layer one neurons: 128\n",
      "layer two neurons: 128\n",
      "Epoch 00012: early stopping\n",
      "Elapsed time: 0:00:52.25\n",
      "Accuracy: 0.6912\n",
      "F1 Score: 0.6898099579455357\n",
      "Layer One: 256\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71      1000\n",
      "           1       0.80      0.82      0.81      1000\n",
      "           2       0.61      0.52      0.56      1000\n",
      "           3       0.53      0.51      0.52      1000\n",
      "           4       0.64      0.64      0.64      1000\n",
      "           5       0.55      0.62      0.58      1000\n",
      "           6       0.70      0.81      0.75      1000\n",
      "           7       0.79      0.68      0.73      1000\n",
      "           8       0.74      0.86      0.80      1000\n",
      "           9       0.82      0.77      0.79      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.6898099579455357\n",
      "layer one neurons: 256\n",
      "layer two neurons: 16\n",
      "Epoch 00012: early stopping\n",
      "Elapsed time: 0:00:52.90\n",
      "Accuracy: 0.7044\n",
      "F1 Score: 0.7031413935717774\n",
      "Layer One: 256\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72      1000\n",
      "           1       0.79      0.82      0.81      1000\n",
      "           2       0.60      0.63      0.62      1000\n",
      "           3       0.56      0.52      0.54      1000\n",
      "           4       0.67      0.67      0.67      1000\n",
      "           5       0.62      0.57      0.59      1000\n",
      "           6       0.77      0.79      0.78      1000\n",
      "           7       0.72      0.78      0.75      1000\n",
      "           8       0.80      0.82      0.81      1000\n",
      "           9       0.90      0.63      0.74      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.7031413935717774\n",
      "layer one neurons: 256\n",
      "layer two neurons: 32\n",
      "Epoch 00010: early stopping\n",
      "Elapsed time: 0:00:46.24\n",
      "Accuracy: 0.7005\n",
      "F1 Score: 0.7014570911846808\n",
      "Layer One: 256\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.67      0.72      1000\n",
      "           1       0.87      0.75      0.81      1000\n",
      "           2       0.62      0.60      0.61      1000\n",
      "           3       0.54      0.51      0.53      1000\n",
      "           4       0.60      0.70      0.65      1000\n",
      "           5       0.56      0.64      0.59      1000\n",
      "           6       0.82      0.73      0.78      1000\n",
      "           7       0.79      0.71      0.75      1000\n",
      "           8       0.76      0.85      0.80      1000\n",
      "           9       0.72      0.85      0.78      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.7014570911846808\n",
      "layer one neurons: 256\n",
      "layer two neurons: 64\n",
      "Epoch 00010: early stopping\n",
      "Elapsed time: 0:00:47.59\n",
      "Accuracy: 0.7103\n",
      "F1 Score: 0.7107345640349594\n",
      "Layer One: 256\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74      1000\n",
      "           1       0.79      0.86      0.83      1000\n",
      "           2       0.68      0.55      0.61      1000\n",
      "           3       0.51      0.54      0.53      1000\n",
      "           4       0.60      0.76      0.67      1000\n",
      "           5       0.59      0.62      0.61      1000\n",
      "           6       0.77      0.77      0.77      1000\n",
      "           7       0.76      0.76      0.76      1000\n",
      "           8       0.83      0.81      0.82      1000\n",
      "           9       0.82      0.75      0.78      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:adam\n",
      "f1 score:0.7107345640349594\n",
      "layer one neurons: 256\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:52.33\n",
      "Accuracy: 0.5601\n",
      "F1 Score: 0.5573463559528157\n",
      "Layer One: 32\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58      1000\n",
      "           1       0.66      0.65      0.65      1000\n",
      "           2       0.46      0.38      0.42      1000\n",
      "           3       0.43      0.34      0.38      1000\n",
      "           4       0.47      0.57      0.52      1000\n",
      "           5       0.45      0.48      0.47      1000\n",
      "           6       0.64      0.66      0.65      1000\n",
      "           7       0.57      0.67      0.61      1000\n",
      "           8       0.70      0.66      0.68      1000\n",
      "           9       0.59      0.65      0.62      1000\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.56      0.56      0.56     10000\n",
      "weighted avg       0.56      0.56      0.56     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5573463559528157\n",
      "layer one neurons: 32\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:52.21\n",
      "Accuracy: 0.5585\n",
      "F1 Score: 0.5503629644617347\n",
      "Layer One: 32\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61      1000\n",
      "           1       0.60      0.73      0.66      1000\n",
      "           2       0.46      0.41      0.44      1000\n",
      "           3       0.46      0.34      0.39      1000\n",
      "           4       0.52      0.41      0.46      1000\n",
      "           5       0.50      0.41      0.45      1000\n",
      "           6       0.56      0.74      0.64      1000\n",
      "           7       0.61      0.64      0.62      1000\n",
      "           8       0.62      0.71      0.66      1000\n",
      "           9       0.58      0.58      0.58      1000\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.55      0.56      0.55     10000\n",
      "weighted avg       0.55      0.56      0.55     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5503629644617347\n",
      "layer one neurons: 32\n",
      "layer two neurons: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:00:53.20\n",
      "Accuracy: 0.5735\n",
      "F1 Score: 0.5668701821711363\n",
      "Layer One: 32\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61      1000\n",
      "           1       0.65      0.74      0.70      1000\n",
      "           2       0.49      0.39      0.43      1000\n",
      "           3       0.46      0.35      0.40      1000\n",
      "           4       0.51      0.48      0.50      1000\n",
      "           5       0.52      0.42      0.47      1000\n",
      "           6       0.49      0.81      0.61      1000\n",
      "           7       0.66      0.64      0.65      1000\n",
      "           8       0.67      0.73      0.70      1000\n",
      "           9       0.63      0.61      0.62      1000\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.57      0.57      0.57     10000\n",
      "weighted avg       0.57      0.57      0.57     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5668701821711363\n",
      "layer one neurons: 32\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:00:53.28\n",
      "Accuracy: 0.5897\n",
      "F1 Score: 0.5796277680854672\n",
      "Layer One: 32\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64      1000\n",
      "           1       0.61      0.80      0.70      1000\n",
      "           2       0.53      0.40      0.45      1000\n",
      "           3       0.47      0.36      0.41      1000\n",
      "           4       0.56      0.53      0.54      1000\n",
      "           5       0.56      0.39      0.46      1000\n",
      "           6       0.62      0.74      0.67      1000\n",
      "           7       0.58      0.70      0.63      1000\n",
      "           8       0.63      0.75      0.69      1000\n",
      "           9       0.65      0.56      0.60      1000\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.58      0.59      0.58     10000\n",
      "weighted avg       0.58      0.59      0.58     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5796277680854672\n",
      "layer one neurons: 32\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:53.20\n",
      "Accuracy: 0.5677\n",
      "F1 Score: 0.5659773295995426\n",
      "Layer One: 64\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59      1000\n",
      "           1       0.62      0.74      0.68      1000\n",
      "           2       0.46      0.40      0.43      1000\n",
      "           3       0.39      0.43      0.41      1000\n",
      "           4       0.56      0.45      0.50      1000\n",
      "           5       0.47      0.51      0.49      1000\n",
      "           6       0.71      0.58      0.64      1000\n",
      "           7       0.64      0.65      0.65      1000\n",
      "           8       0.63      0.72      0.67      1000\n",
      "           9       0.60      0.63      0.61      1000\n",
      "\n",
      "    accuracy                           0.57     10000\n",
      "   macro avg       0.57      0.57      0.57     10000\n",
      "weighted avg       0.57      0.57      0.57     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5659773295995426\n",
      "layer one neurons: 64\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:53.84\n",
      "Accuracy: 0.5802\n",
      "F1 Score: 0.5764780944467909\n",
      "Layer One: 64\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62      1000\n",
      "           1       0.69      0.67      0.68      1000\n",
      "           2       0.46      0.46      0.46      1000\n",
      "           3       0.46      0.37      0.41      1000\n",
      "           4       0.55      0.44      0.49      1000\n",
      "           5       0.49      0.49      0.49      1000\n",
      "           6       0.64      0.69      0.66      1000\n",
      "           7       0.59      0.68      0.63      1000\n",
      "           8       0.67      0.72      0.69      1000\n",
      "           9       0.59      0.64      0.61      1000\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.58      0.58      0.58     10000\n",
      "weighted avg       0.58      0.58      0.58     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5764780944467909\n",
      "layer one neurons: 64\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:00:54.42\n",
      "Accuracy: 0.5993\n",
      "F1 Score: 0.5975783286711731\n",
      "Layer One: 64\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64      1000\n",
      "           1       0.69      0.76      0.72      1000\n",
      "           2       0.44      0.53      0.48      1000\n",
      "           3       0.46      0.40      0.43      1000\n",
      "           4       0.62      0.43      0.51      1000\n",
      "           5       0.47      0.55      0.51      1000\n",
      "           6       0.64      0.74      0.68      1000\n",
      "           7       0.71      0.63      0.67      1000\n",
      "           8       0.67      0.74      0.70      1000\n",
      "           9       0.70      0.59      0.64      1000\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.60      0.60      0.60     10000\n",
      "weighted avg       0.60      0.60      0.60     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5975783286711731\n",
      "layer one neurons: 64\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:00:55.59\n",
      "Accuracy: 0.6054\n",
      "F1 Score: 0.6027332282129155\n",
      "Layer One: 64\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1000\n",
      "           1       0.73      0.73      0.73      1000\n",
      "           2       0.56      0.40      0.47      1000\n",
      "           3       0.43      0.40      0.41      1000\n",
      "           4       0.57      0.50      0.54      1000\n",
      "           5       0.46      0.60      0.52      1000\n",
      "           6       0.62      0.73      0.67      1000\n",
      "           7       0.65      0.67      0.66      1000\n",
      "           8       0.73      0.71      0.72      1000\n",
      "           9       0.66      0.66      0.66      1000\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.61      0.61      0.60     10000\n",
      "weighted avg       0.61      0.61      0.60     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.6027332282129155\n",
      "layer one neurons: 64\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:00:57.38\n",
      "Accuracy: 0.5612\n",
      "F1 Score: 0.5575720976385701\n",
      "Layer One: 128\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59      1000\n",
      "           1       0.63      0.71      0.66      1000\n",
      "           2       0.48      0.41      0.44      1000\n",
      "           3       0.40      0.45      0.42      1000\n",
      "           4       0.55      0.44      0.49      1000\n",
      "           5       0.49      0.41      0.45      1000\n",
      "           6       0.59      0.70      0.64      1000\n",
      "           7       0.65      0.60      0.62      1000\n",
      "           8       0.62      0.73      0.67      1000\n",
      "           9       0.59      0.58      0.58      1000\n",
      "\n",
      "    accuracy                           0.56     10000\n",
      "   macro avg       0.56      0.56      0.56     10000\n",
      "weighted avg       0.56      0.56      0.56     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5575720976385701\n",
      "layer one neurons: 128\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:00:57.96\n",
      "Accuracy: 0.5863\n",
      "F1 Score: 0.5824520979331915\n",
      "Layer One: 128\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62      1000\n",
      "           1       0.67      0.73      0.70      1000\n",
      "           2       0.48      0.43      0.45      1000\n",
      "           3       0.46      0.39      0.42      1000\n",
      "           4       0.49      0.56      0.52      1000\n",
      "           5       0.51      0.43      0.47      1000\n",
      "           6       0.58      0.75      0.66      1000\n",
      "           7       0.65      0.66      0.65      1000\n",
      "           8       0.69      0.71      0.70      1000\n",
      "           9       0.62      0.63      0.63      1000\n",
      "\n",
      "    accuracy                           0.59     10000\n",
      "   macro avg       0.58      0.59      0.58     10000\n",
      "weighted avg       0.58      0.59      0.58     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5824520979331915\n",
      "layer one neurons: 128\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:00:58.71\n",
      "Accuracy: 0.6166\n",
      "F1 Score: 0.6179634197953643\n",
      "Layer One: 128\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      1000\n",
      "           1       0.74      0.71      0.73      1000\n",
      "           2       0.48      0.52      0.50      1000\n",
      "           3       0.43      0.47      0.45      1000\n",
      "           4       0.63      0.50      0.56      1000\n",
      "           5       0.51      0.55      0.53      1000\n",
      "           6       0.75      0.66      0.70      1000\n",
      "           7       0.66      0.69      0.68      1000\n",
      "           8       0.70      0.73      0.72      1000\n",
      "           9       0.68      0.67      0.68      1000\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.62      0.62      0.62     10000\n",
      "weighted avg       0.62      0.62      0.62     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.6179634197953643\n",
      "layer one neurons: 128\n",
      "layer two neurons: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:01:01.15\n",
      "Accuracy: 0.6248\n",
      "F1 Score: 0.6235923163883709\n",
      "Layer One: 128\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.66      1000\n",
      "           1       0.72      0.76      0.74      1000\n",
      "           2       0.52      0.47      0.49      1000\n",
      "           3       0.47      0.42      0.45      1000\n",
      "           4       0.54      0.61      0.57      1000\n",
      "           5       0.51      0.56      0.53      1000\n",
      "           6       0.70      0.73      0.71      1000\n",
      "           7       0.70      0.69      0.69      1000\n",
      "           8       0.70      0.75      0.72      1000\n",
      "           9       0.72      0.62      0.67      1000\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.62      0.62      0.62     10000\n",
      "weighted avg       0.62      0.62      0.62     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.6235923163883709\n",
      "layer one neurons: 128\n",
      "layer two neurons: 128\n",
      "Elapsed time: 0:01:04.74\n",
      "Accuracy: 0.5508\n",
      "F1 Score: 0.5408775972671519\n",
      "Layer One: 256\n",
      "Layer Two: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.63      0.59      1000\n",
      "           1       0.55      0.77      0.64      1000\n",
      "           2       0.48      0.35      0.40      1000\n",
      "           3       0.47      0.32      0.38      1000\n",
      "           4       0.53      0.45      0.49      1000\n",
      "           5       0.51      0.39      0.44      1000\n",
      "           6       0.60      0.68      0.63      1000\n",
      "           7       0.60      0.64      0.62      1000\n",
      "           8       0.62      0.69      0.66      1000\n",
      "           9       0.53      0.60      0.56      1000\n",
      "\n",
      "    accuracy                           0.55     10000\n",
      "   macro avg       0.54      0.55      0.54     10000\n",
      "weighted avg       0.54      0.55      0.54     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5408775972671519\n",
      "layer one neurons: 256\n",
      "layer two neurons: 16\n",
      "Elapsed time: 0:01:07.90\n",
      "Accuracy: 0.5841\n",
      "F1 Score: 0.5812338921806827\n",
      "Layer One: 256\n",
      "Layer Two: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63      1000\n",
      "           1       0.66      0.72      0.69      1000\n",
      "           2       0.47      0.47      0.47      1000\n",
      "           3       0.42      0.40      0.41      1000\n",
      "           4       0.56      0.46      0.51      1000\n",
      "           5       0.49      0.45      0.47      1000\n",
      "           6       0.60      0.73      0.66      1000\n",
      "           7       0.62      0.68      0.65      1000\n",
      "           8       0.72      0.69      0.71      1000\n",
      "           9       0.61      0.63      0.62      1000\n",
      "\n",
      "    accuracy                           0.58     10000\n",
      "   macro avg       0.58      0.58      0.58     10000\n",
      "weighted avg       0.58      0.58      0.58     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5812338921806827\n",
      "layer one neurons: 256\n",
      "layer two neurons: 32\n",
      "Elapsed time: 0:01:08.89\n",
      "Accuracy: 0.6001\n",
      "F1 Score: 0.5981696760345763\n",
      "Layer One: 256\n",
      "Layer Two: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1000\n",
      "           1       0.73      0.65      0.69      1000\n",
      "           2       0.54      0.43      0.48      1000\n",
      "           3       0.42      0.47      0.45      1000\n",
      "           4       0.60      0.45      0.51      1000\n",
      "           5       0.49      0.52      0.51      1000\n",
      "           6       0.64      0.73      0.68      1000\n",
      "           7       0.63      0.71      0.67      1000\n",
      "           8       0.70      0.72      0.71      1000\n",
      "           9       0.62      0.67      0.64      1000\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.60      0.60      0.60     10000\n",
      "weighted avg       0.60      0.60      0.60     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.5981696760345763\n",
      "layer one neurons: 256\n",
      "layer two neurons: 64\n",
      "Elapsed time: 0:01:10.86\n",
      "Accuracy: 0.6209\n",
      "F1 Score: 0.6178594179579966\n",
      "Layer One: 256\n",
      "Layer Two: 128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66      1000\n",
      "           1       0.70      0.76      0.73      1000\n",
      "           2       0.48      0.51      0.49      1000\n",
      "           3       0.48      0.41      0.44      1000\n",
      "           4       0.64      0.47      0.54      1000\n",
      "           5       0.52      0.53      0.52      1000\n",
      "           6       0.69      0.73      0.71      1000\n",
      "           7       0.69      0.68      0.69      1000\n",
      "           8       0.72      0.73      0.72      1000\n",
      "           9       0.70      0.65      0.67      1000\n",
      "\n",
      "    accuracy                           0.62     10000\n",
      "   macro avg       0.62      0.62      0.62     10000\n",
      "weighted avg       0.62      0.62      0.62     10000\n",
      "\n",
      "activation:tanh\n",
      "optimizer:sgd\n",
      "f1 score:0.6178594179579966\n",
      "layer one neurons: 256\n",
      "layer two neurons: 128\n",
      "Training has completed. Model information stored in best_model[1].\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"cnn/best_weights.hdf5\", verbose=0, save_best_only=True) \n",
    "\n",
    "activations = ['relu', 'sigmoid', 'tanh']\n",
    "optimizers = ['adam', 'sgd']\n",
    "layer_one = [32, 64 ,128, 256]\n",
    "layer_two = [16, 32, 64, 128]\n",
    "batch_size = 128\n",
    "\n",
    "# score, model, neuron count, (activation, optimizer)\n",
    "best_model = (0, None, None, None)\n",
    "\n",
    "# loop through configurations\n",
    "for activation in activations:\n",
    "    for optimizer in optimizers:\n",
    "        for neuron_i in layer_one:\n",
    "            for neuron_j in layer_two:\n",
    "                #define model\n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(\n",
    "                    Conv2D(\n",
    "                        32,                             # from input shape\n",
    "                        kernel_size=(3,3),              \n",
    "                        strides=(2,2),                  # 2x2 stride\n",
    "                        padding='same',                 # pad with zeros if it goes over\n",
    "                        activation=activation,          # for the loop\n",
    "                        input_shape=x_train.shape[1:]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # variable neuron count\n",
    "                model.add(Conv2D(neuron_i, (3, 3), padding='same'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "                model.add(\n",
    "                    Conv2D(\n",
    "                        neuron_j,\n",
    "                        kernel_size=(3,3),\n",
    "                        strides=(1,1),\n",
    "                        padding='same',\n",
    "                        activation=activation\n",
    "                    )\n",
    "                )\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "                model.add(Flatten())\n",
    "\n",
    "                model.add(Dense(512))\n",
    "                model.add(Activation(activation))\n",
    "                model.add(Dropout(0.5))\n",
    "\n",
    "                # there should be 10 possible outputs\n",
    "                model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "                # compile model\n",
    "                model.compile(\n",
    "                    loss='categorical_crossentropy', \n",
    "                    optimizer = optimizer\n",
    "                )\n",
    "\n",
    "                # early stoppping\n",
    "                monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                # fit the model\n",
    "                model.fit(x_train, y_train, batch_size=batch_size, callbacks=[monitor, checkpointer], epochs=15, verbose=0, validation_data=(x_test, y_test))\n",
    "\n",
    "                elapsed = time.time() - start\n",
    "                print (\"Elapsed time: {}\".format(hms_string(elapsed)))\n",
    "\n",
    "                pred = model.predict(x_test)\n",
    "                pred = np.argmax(pred,axis=1)\n",
    "                y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "                score = metrics.accuracy_score(y_true, pred) \n",
    "                f1_score = metrics.f1_score(y_true, pred, average='weighted')\n",
    "\n",
    "                print('Accuracy: {}'.format(score))\n",
    "                print('F1 Score: {}'.format(f1_score))\n",
    "                print('Layer One: {}'.format(neuron_i))\n",
    "                print('Layer Two: {}'.format(neuron_j))\n",
    "\n",
    "                print(metrics.classification_report(y_true, pred))\n",
    "\n",
    "                print('activation:{}\\noptimizer:{}\\nf1 score:{}\\nlayer one neurons: {}\\nlayer two neurons: {}'.format(activation, optimizer, f1_score, neuron_i, neuron_j))\n",
    "\n",
    "                # set new best model manually\n",
    "                if f1_score > best_model[0]:\n",
    "                    best_model = (score, model, (neuron_i, neuron_j), (activation, optimizer))\n",
    "                    print('[BEST MODEL UPDATED] F1 Score: ' + str(best_model[0]))\n",
    "                    print('[BEST MODEL UPDATED] Hyperparameters: ({}, {})'.format(best_model[3][0], best_model[3][1]))\n",
    "\n",
    "print('Training has completed. Model information stored in best_model[1].')\n",
    "\n",
    "# take best model\n",
    "model = best_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "-i8FM7FiKJ73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7642\n",
      "Neurons: 128, 64\n",
      "('relu', 'adam')\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_93 (Conv2D)           (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 8, 8, 64)          73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 641,610\n",
      "Trainable params: 641,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(str(best_model[0]))\n",
    "print(\"Neurons: {}, {}\".format(best_model[2][0], best_model[2][1]))\n",
    "print(str(best_model[3]))\n",
    "best_model[1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tt-DqAqLoxOO"
   },
   "source": [
    "## Convolutional Neural Network Model \n",
    "\n",
    "* Conv2D\n",
    "* Activation\n",
    "* MaxPooling2D\n",
    "* Dropout\n",
    "* Flatten\n",
    "* Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "Lo9sIJWKJNPY"
   },
   "outputs": [],
   "source": [
    "# use best model\n",
    "convnet = best_model[1]\n",
    "convnet.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "fIvcQlgwU2HJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_351 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_352 (Conv2D)          (None, 32, 32, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_228 (MaxPoolin (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_353 (Conv2D)          (None, 16, 16, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_229 (MaxPoolin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_125 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,173,514\n",
      "Trainable params: 2,173,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print model summary\n",
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YZPf35U0eIA2",
    "outputId": "7a916ed6-c27c-4436-f120-a775965a0365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 - 11s - loss: 1.9494 - acc: 0.3838 - val_loss: 1.2233 - val_acc: 0.5596\n",
      "Epoch 2/100\n",
      "50000/50000 - 7s - loss: 1.2400 - acc: 0.5626 - val_loss: 1.0777 - val_acc: 0.6177\n",
      "Epoch 3/100\n",
      "50000/50000 - 6s - loss: 1.0457 - acc: 0.6312 - val_loss: 0.9588 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "50000/50000 - 7s - loss: 0.9610 - acc: 0.6609 - val_loss: 0.9378 - val_acc: 0.6719\n",
      "Epoch 5/100\n",
      "50000/50000 - 7s - loss: 0.9119 - acc: 0.6790 - val_loss: 0.9641 - val_acc: 0.6624\n",
      "Epoch 6/100\n",
      "50000/50000 - 7s - loss: 0.8693 - acc: 0.6929 - val_loss: 0.9984 - val_acc: 0.6516\n",
      "Epoch 7/100\n",
      "50000/50000 - 7s - loss: 0.8361 - acc: 0.7053 - val_loss: 0.8817 - val_acc: 0.6940\n",
      "Epoch 8/100\n",
      "50000/50000 - 7s - loss: 0.8152 - acc: 0.7148 - val_loss: 0.9004 - val_acc: 0.6849\n",
      "Epoch 9/100\n",
      "50000/50000 - 7s - loss: 0.8012 - acc: 0.7177 - val_loss: 0.8640 - val_acc: 0.7024\n",
      "Epoch 10/100\n",
      "50000/50000 - 6s - loss: 0.7790 - acc: 0.7255 - val_loss: 0.8774 - val_acc: 0.6912\n",
      "Epoch 11/100\n",
      "50000/50000 - 7s - loss: 0.7683 - acc: 0.7288 - val_loss: 0.8908 - val_acc: 0.6913\n",
      "Epoch 12/100\n",
      "50000/50000 - 7s - loss: 0.7630 - acc: 0.7307 - val_loss: 0.8748 - val_acc: 0.6994\n",
      "Epoch 13/100\n",
      "50000/50000 - 7s - loss: 0.7504 - acc: 0.7355 - val_loss: 0.9449 - val_acc: 0.6809\n",
      "Epoch 14/100\n",
      "50000/50000 - 6s - loss: 0.7432 - acc: 0.7364 - val_loss: 0.8825 - val_acc: 0.6986\n",
      "Epoch 00014: early stopping\n",
      "Elapsed time: 0:01:40.41\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "start = time.time()\n",
    "\n",
    "# train convnet\n",
    "convnet.fit(x_train, y_train, batch_size=batch_size, callbacks=[monitor, checkpointer], epochs=100, verbose=2, validation_data=(x_test, y_test))\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print (\"Elapsed time: {}\".format(hms_string(elapsed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUHYFsUEpmU6"
   },
   "source": [
    "## Model Precision, Recall, F1 Score, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "McZsVrRmfDOG",
    "outputId": "e15c651e-37c1-4565-e150-f3199bdb058a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1000\n",
      "           1       0.88      0.74      0.80      1000\n",
      "           2       0.64      0.51      0.57      1000\n",
      "           3       0.54      0.47      0.50      1000\n",
      "           4       0.66      0.68      0.67      1000\n",
      "           5       0.51      0.72      0.60      1000\n",
      "           6       0.74      0.81      0.77      1000\n",
      "           7       0.77      0.71      0.74      1000\n",
      "           8       0.83      0.80      0.81      1000\n",
      "           9       0.74      0.82      0.78      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = convnet.predict(x_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(metrics.classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JAAHrUlEgryO",
    "outputId": "78ef3896-4b2d-4c83-e187-fe98872e808f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[838  19  27  14  12   1   9   6  45  29]\n",
      " [ 15 873   3   5   5   1  11   3  20  64]\n",
      " [ 73   6 616  44  76  53  72  39  17   4]\n",
      " [ 24   9  55 537  75 142  79  44  15  20]\n",
      " [ 16   4  44  39 737  32  56  60  10   2]\n",
      " [ 15   7  32 138  54 642  33  63   9   7]\n",
      " [  8   3  20  32  32  16 871   7   7   4]\n",
      " [ 12   3  14  32  52  34   7 832   3  11]\n",
      " [ 68  31   6   8   3   3   6   1 855  19]\n",
      " [ 32  84   5  10   5   3   9   5  24 823]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_true, pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_matrix, ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCAWQB0KpyOx"
   },
   "source": [
    "## Convolutional Neural Network Predictions\n",
    "The following cells will predict 5 random images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DO3qOZ3ijlM3"
   },
   "outputs": [],
   "source": [
    "x_sample = []\n",
    "for x in x_test:\n",
    "  img = skimage.transform.resize(x, (64, 64))\n",
    "  x_sample.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wcE9qxXtheh1",
    "outputId": "aa511c0b-b205-41df-f352-128abff0a51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: automobile\n",
      "Actual: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x206D877A548>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: truck\n",
      "Actual: ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x206D878DBC8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: deer\n",
      "Actual: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x206D877AA48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: dog\n",
      "Actual: dog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x206D878DBC8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: dog\n",
      "Actual: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x206D878D8C8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random as rand\n",
    "\n",
    "labels = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "rand_range = rand.randint(5, 10001)\n",
    "i = rand_range - 5\n",
    "\n",
    "for i in range(i, rand_range):\n",
    "  print(\"Prediction: {}\".format(labels[pred[i]]))\n",
    "  print(\"Actual: {}\".format(labels[y_true[i]]))\n",
    "  pixels = x_sample[i].reshape(64, 64, 3)\n",
    "  pixels = (pixels * 64) + 64\n",
    "  pixels = pixels.astype(np.uint8)\n",
    "\n",
    "  pic = Image.fromarray(pixels, 'RGB')\n",
    "  display(pic)\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZgeXPZnf289"
   },
   "source": [
    "## Part II:   CNN model with Transfer Learning\n",
    "In this section, we if we can improve the previous model using the transfer learning technique. To accomplish this, we are using [VGG16](https://neurohive.io/en/popular-networks/vgg16/), a pre-trained model.\n",
    "\n",
    "### Additional Notes\n",
    "* VGG16 supports down to 48x48 images as an input, which conflicts with *our* 32x32 image resolution, and thus, we will upsaample our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SCOVkRXff4dt",
    "outputId": "7e68faff-297f-47f6-9706-7f85f6c6e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Reload data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "V6dFHEATf9NB"
   },
   "outputs": [],
   "source": [
    "import skimage.transform\n",
    "from skimage.transform import resize\n",
    "\n",
    "new_x_train = []\n",
    "\n",
    "for x in x_train:\n",
    "  img = skimage.transform.resize(x, (64, 64))\n",
    "  new_x_train.append(img)\n",
    "    \n",
    "# this process may take about a few minutes ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "4NTydC5Wf_Jj"
   },
   "outputs": [],
   "source": [
    "new_x_test = []\n",
    "\n",
    "for x in x_test:\n",
    "  img = skimage.transform.resize(x, (64, 64))\n",
    "  new_x_test.append(img)\n",
    "\n",
    "# this process may take about a few minutes ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "By5Md8MbKiFy"
   },
   "outputs": [],
   "source": [
    "new_x_train = np.asarray(new_x_train)\n",
    "new_x_test = np.asarray(new_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le5pHdFsgBi-"
   },
   "source": [
    "## One Hot Encoding\n",
    "In the following cells, we convert y_train and y_test into 1D images by using reshape(). One-hot encoding is subsequently performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "zO5HpQk4gCmE"
   },
   "outputs": [],
   "source": [
    "#convert y_train and y_test from 2D to 1D\n",
    "y_train = y_train.reshape(50000)\n",
    "y_test = y_test.reshape(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "AiQs_A6KgMUd"
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to one hot format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "V7U7qvzEgDCr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# double check shape\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# expected output:  (50000, 10)\n",
    "# expected output:  (10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "EmNAdZwhzzpF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 64, 64, 3)\n",
      "(10000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(new_x_train.shape)\n",
    "print(new_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyhLsMTAgFX1"
   },
   "source": [
    "## Load the VGG16 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "yB4Be4YzgGKG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))   #  first hidden layer\n",
    "\n",
    "transfer_model = Sequential()\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "  transfer_model.add(layer)\n",
    "\n",
    "# print out the model summary\n",
    "transfer_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcLgBDlqgIYt"
   },
   "source": [
    "## Freeze model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "YwYEuNLfgJIa"
   },
   "outputs": [],
   "source": [
    "for layer in transfer_model.layers:\n",
    "  layer.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuFVBus5gJ-7"
   },
   "source": [
    "###  Write your code in the cell below to add some \"Dense\" layers as top layers.\n",
    "\n",
    "- Donot forget the output layer\n",
    "- Choose the right activation fucntion for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "qaHpaw2HgNaH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_124 (Flatten)        (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 15,929,290\n",
      "Trainable params: 1,214,602\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.add(Flatten())\n",
    "\n",
    "# Add some \"Dense\" layers here, including output layer\n",
    "transfer_model.add(Dense(512))\n",
    "transfer_model.add(Activation(best_model[3][0]))\n",
    "transfer_model.add(Dropout(0.5))\n",
    "transfer_model.add(Dense(256, activation = best_model[3][0]))\n",
    "transfer_model.add(Dense(128, activation = best_model[3][0]))\n",
    "transfer_model.add(Dropout(0.5))\n",
    "\n",
    "#output layer\n",
    "transfer_model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# print out the model summary\n",
    "transfer_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NJE5vnygPE_"
   },
   "source": [
    "## Compile and fit transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "vRxp5fKugQSK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 - 35s - loss: 1.5090 - acc: 0.4745 - val_loss: 1.0954 - val_acc: 0.6231\n",
      "Epoch 2/100\n",
      "50000/50000 - 18s - loss: 1.1855 - acc: 0.5997 - val_loss: 0.9915 - val_acc: 0.6617\n",
      "Epoch 3/100\n",
      "50000/50000 - 18s - loss: 1.0916 - acc: 0.6346 - val_loss: 0.9860 - val_acc: 0.6613\n",
      "Epoch 4/100\n",
      "50000/50000 - 18s - loss: 1.0439 - acc: 0.6479 - val_loss: 0.9341 - val_acc: 0.6797\n",
      "Epoch 5/100\n",
      "50000/50000 - 18s - loss: 1.0054 - acc: 0.6609 - val_loss: 0.9213 - val_acc: 0.6799\n",
      "Epoch 6/100\n",
      "50000/50000 - 18s - loss: 0.9670 - acc: 0.6730 - val_loss: 0.9141 - val_acc: 0.6916\n",
      "Epoch 7/100\n",
      "50000/50000 - 18s - loss: 0.9426 - acc: 0.6835 - val_loss: 0.8943 - val_acc: 0.6934\n",
      "Epoch 8/100\n",
      "50000/50000 - 18s - loss: 0.9128 - acc: 0.6895 - val_loss: 0.8951 - val_acc: 0.6928\n",
      "Epoch 9/100\n",
      "50000/50000 - 18s - loss: 0.8961 - acc: 0.6972 - val_loss: 0.8715 - val_acc: 0.7013\n",
      "Epoch 10/100\n",
      "50000/50000 - 18s - loss: 0.8804 - acc: 0.7030 - val_loss: 0.8690 - val_acc: 0.7010\n",
      "Epoch 11/100\n",
      "50000/50000 - 18s - loss: 0.8543 - acc: 0.7088 - val_loss: 0.8688 - val_acc: 0.7013\n",
      "Epoch 12/100\n",
      "50000/50000 - 18s - loss: 0.8356 - acc: 0.7159 - val_loss: 0.8772 - val_acc: 0.6975\n",
      "Epoch 13/100\n",
      "50000/50000 - 19s - loss: 0.8335 - acc: 0.7202 - val_loss: 0.8595 - val_acc: 0.7041\n",
      "Epoch 14/100\n",
      "50000/50000 - 23s - loss: 0.8166 - acc: 0.7224 - val_loss: 0.8507 - val_acc: 0.7094\n",
      "Epoch 15/100\n",
      "50000/50000 - 20s - loss: 0.7983 - acc: 0.7268 - val_loss: 0.8559 - val_acc: 0.7084\n",
      "Epoch 16/100\n",
      "50000/50000 - 20s - loss: 0.7851 - acc: 0.7318 - val_loss: 0.8513 - val_acc: 0.7079\n",
      "Epoch 17/100\n",
      "50000/50000 - 19s - loss: 0.7789 - acc: 0.7349 - val_loss: 0.8493 - val_acc: 0.7136\n",
      "Epoch 18/100\n",
      "50000/50000 - 19s - loss: 0.7564 - acc: 0.7432 - val_loss: 0.8461 - val_acc: 0.7088\n",
      "Epoch 19/100\n",
      "50000/50000 - 19s - loss: 0.7488 - acc: 0.7449 - val_loss: 0.8571 - val_acc: 0.7098\n",
      "Epoch 20/100\n",
      "50000/50000 - 19s - loss: 0.7358 - acc: 0.7492 - val_loss: 0.8816 - val_acc: 0.7034\n",
      "Epoch 21/100\n",
      "50000/50000 - 18s - loss: 0.7244 - acc: 0.7515 - val_loss: 0.8522 - val_acc: 0.7110\n",
      "Epoch 22/100\n",
      "50000/50000 - 21s - loss: 0.7157 - acc: 0.7546 - val_loss: 0.8597 - val_acc: 0.7104\n",
      "Epoch 23/100\n",
      "50000/50000 - 22s - loss: 0.7075 - acc: 0.7556 - val_loss: 0.8583 - val_acc: 0.7093\n",
      "Epoch 00023: early stopping\n",
      "Elapsed time: 0:07:39.56\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"cnn/best_weights_transfer.hdf5\", verbose=0, save_best_only=True) \n",
    "\n",
    "# compile transfer_model\n",
    "transfer_model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=2, mode='auto')\n",
    "      \n",
    "start = time.time()\n",
    "\n",
    "transfer_model.fit(new_x_train, y_train, batch_size, callbacks=[monitor, checkpointer], epochs=100, verbose=2, validation_data=(new_x_test, y_test))\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print (\"Elapsed time: {}\".format(hms_string(elapsed)))\n",
    "\n",
    "# since we use GPU, the training time for each epoch for the transferred model is about 60 seconds.  \n",
    "# Let it run for a few epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk-4tYl0gSPx"
   },
   "source": [
    "## Model Precision, Recall, F1 Score, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "FDDjqdWrgSyr"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred = transfer_model.predict(new_x_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7093\n",
      "F1 Score: 0.7084612672685883\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print(\"Accuracy: {}\".format(score))\n",
    "\n",
    "f1 = metrics.f1_score(y_true, pred, average='weighted')\n",
    "print(\"F1 Score: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1000\n",
      "           1       0.88      0.72      0.80      1000\n",
      "           2       0.73      0.59      0.65      1000\n",
      "           3       0.56      0.48      0.51      1000\n",
      "           4       0.65      0.67      0.66      1000\n",
      "           5       0.59      0.67      0.63      1000\n",
      "           6       0.65      0.78      0.71      1000\n",
      "           7       0.70      0.79      0.74      1000\n",
      "           8       0.82      0.83      0.83      1000\n",
      "           9       0.80      0.79      0.79      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[776   9  44  16  25   9  16  23  63  19]\n",
      " [ 29 724   7  27  10  16  24  17  42 104]\n",
      " [ 53   1 595  39  95  70  96  43   6   2]\n",
      " [ 24   8  45 476  58 197 112  48  12  20]\n",
      " [ 21   1  33  48 668  39  78  91  12   9]\n",
      " [  7   2  23 117  54 672  43  64   7  11]\n",
      " [  6   9  35  57  46  52 778   6   8   3]\n",
      " [ 12   4  26  26  50  67  17 789   4   5]\n",
      " [ 62  16   9  14   9   5  16  13 828  28]\n",
      " [ 39  47   3  30  13  12   8  38  23 787]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_true, pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(conf_matrix, ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sw95GsZgU3P"
   },
   "source": [
    "## Transfer Learning Model Predictions\n",
    "The following cells will predict the same 5 images as previously using the transfer learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "iyYmHhg5gWIK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: automobile\n",
      "Actual: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAQDElEQVR4nNV6SZYsSWwjAJpH1tMxe6F1X75VP9ONhBakeURWqQ+gWOQQk3MEAZrz//7n/wGw911ZBmCXAQMGDQL9Tz+HiHi9FIshkLYNo3/ZLjsTZVTh/ZIBGCQhgoIAkAYN2O6rkAQIwHDZWdUfFCFKJOG2pYC003W7AAj/yx8rdwJwGQBhdxz48ZZ+BR1J584ykB2/OsGfiBPQx6drcuDOAMQwQc5LQJUBByWgY2y7qnZllUmIvEQDH0b508TlqrHSv2zmL7PnRZfT25nzCRt13gGQDMokyfMpu8vPBrps2CVlI13pIkCYANjXc9q7qqoIhBSU2Ob210BkkbQBLHtemWqd6/0PybKRVduV9bwZHU+SJCVZ7t44V+u3AICfugenX8q7irACpMLTbbazKqvGatk2OZaRlAKEzbcDbQmBiRo/Lo8nxLBdWVXTYoI6UySgbnrifGCSOsEbT33yWXZ1xfLj0oDxtKllmCf9T+JMkZCqHZjwSh1F2+lCnfxjvvopMXa4QZHqH/2kSHXx0E8aeeDl/XOc62qQIsQICYCrjqmPn8+FDdMwIEDtcztQxzB2d7QFrIkg8dEDnlqBRJCKCFI8hoqEaJyOeSeWhtr6xx53VYkSJQmufJdd5+pXU06K/FmVbwdcZRA0+0oU5AERwN14nnIXYFAREUuK+U69LzUdwoMUg/Ht6dRJW8pxgXxi749U93eYJ50wYKIAwz23VqPIrqopyFhrUQJMTU8RxPSFUWoHqH5ntGddxrbtKoJV7oRKJmH5HzEE7K42Nwj9AwmPDydxPEgIVFUCOzeAtcsAfvbOTBciFqWliQs9HyTe+bVR4JRQu9r1Q9t2ZiYr01ld5UWhnsJ/TLJdmUWwnlxN1Q6wnZ/vKgJYdmVt131vAIsKAGSBBvIgByE9OeQZGw8LkAFQEkWgMyAShB3SZoK7tqe26C7SzrImLLbLRTCJQclPU42OyCSjs0DYqKpdtTMBrOt6AWDEysy9Ra4VDE3biQDPmAJIBTEFciBy5hAoSqLDEsnKyqoyEs7KneUsAViLQAHNeVBOmhJPaU0lnuLqrjiJIIAqV1VVAVivr78AqHbu+x471GGDRAWJZgxgcyt5Br7h6hALpAiRChH9Hu2qnRYPeqHgMsqlM/ngBA9YcDriA3p4Jr6PB4e7nLetv/76AvBz8wdOZxkeOBepWAEgnQdIXWW79t4dX4IKxVqXRArjhoUVVQgVQBcHRQtlyiDU+CvQ1VSTT4/b6myDIs3DeAmYDUGkFQKw+hc2pgj4AQYc93ftyiJMckUYztp778wkufCSbNBspgBSDMR1QWIV6wGB6B6hms8xCBQP65sJQjgaJN4YhHmR79gHAWDd+wZw3/fObQLdiTDZKHFn5vf3n9wJOBR+vURWdhclqYjznR5mSJFSrItS5sa2bYuva4EMCURVNRcFgSa1NAqwBQSpHrrjgsnjQ//rUQKrW6HZDXVcnhoH4J37575zbwIOrxWUZvTqUIrmZ2XR5R4av6hHgwCjy1IAWIXMM3GNpldDBxAcNvzMv+MDaBPQqZJ1qqXZJLtiq5yZVa4GkLtcJmAZhkRqKRR1AQotNtK3RWQi3404gIIz1ygGRapAGlkwEABcgIsDy03DzOMGevABAPRBMNcBd0klCpPG008EwZBMilixQpIEQo4agNGEyCTwAFzLER2Gd4Ld01mCJJFK0VIlvdMmXGia9qFgPga0n+enhCA1dMoRXZCwRLH7vUXqAiwwgmtFKEBOz9Whjc2GSJcz03ZEKKgI2nk0xLQpFSEQiqyMzMwdiTux7c7FESwecv9Yj+nTR5GNGBJZKsPFckdd0vnc+N2fbC1QhhPZpFUViBYdVXXvbF1PtPLwz/2TmTaU7SYirslEu22keh1QPU3ehGOE68O1D0IaAFY2cLRtld6ZmZb0ekmThEO2qod/s9My966qMrFWrCtAZNad++e+XVV2VuL23vvP4BgiVu4v1xfpWOsRdyYLLCCNoOJ1RQiuck/ddJUr7cJvwbWOkOzQ4qgAimra4CNw4bKr0ck+89yjgVu2ZtXee+/tKok2yv3E3byNZNbOWlWlNu+Ej80PF0JaX69rhTuhVa0DRw26MKKwydy0icsOiotUUMG4pEC3IGeH02HocNgmGWQsXWtFhF2uzMyqnNQPa/Ja0epnKVYsDfIetCBIrBUi+71fX6+14sO0mstnZe597/v+aTq2KhNA7U27cWFRVGgFI0ie4UD3GqWyojJLURRBrIhYEaEqKLRWuBaA67pIqBAO8mgXKWJda8Vaok6XCi0UlwlGaK0r4nMXcRwoRy7FpliVANb98wMg9w5yfb3iumItKdpuTucOFjtsq7uqi9OAut/JKuLrayny9SIQ0R1cIHQ09yMhm8KoZHhI/9OfpJo8vRdyrMrJ+Wow584bwPr5+W4HVsR1rQuQFEtvUXEGYssyH1yzTGtm4CwnFLEIrdXSrz8CErFCIxj4fMQwNWQdQBOk7skqk9YgUVVm7l1V3SbXWriu1+sCsL7//EFr4rX2WjtihTxkVNaHIKrWYn52WS6MHOT8ds1Qe7Z2PWTCAepZPR2jXelnyTTAWfMpNfOA7cy99/3dQLyuK/7jPxS6Xq8uoRtD9blz733fpKtmiq6A1NTDZlVfbzx6NOYzOB/MHXlulE2bdOuIo8unOprRdSmefV414xHpIGHnrrwzs3JXgWS5luK6FoCVuQFEhO3Muu/bO0Mazfu6uAKMAitRhaxTA2eTMJsTzmbmzL2ZpQ3iO7dIzeaielC2sqtyZqGp5LN56EUMCFfl7UoBkOAacgq0Vlmker6s64oVJDOz7s2qkPxzcS2sZUUyyqwCQR1bTv0D6JnTgF0ABmQKZTir2WvX+bQ00NKys8UzUFsUiu/CJaygrJwVXLO3ALBerxeAr6+vr6/X9XrR3t/fvm//3EhDP1wLXy98vfj1JUUHWdGin8/ew5V73z8/3/fPz96b4For1iW9CJU92/zeig22GbbOwvcAVatBkJ4tR9s/nyr1Nu1sK1asBWBd17pe1/VqtVtZ3olMZAGJlbTZQoMgeBxwJyBr5/7++f7z999/398/O9uBuK6/vr6g9eqlXQhNExUMgZo++eXSG/U6/NVwGnFyrsHkjtwio58GB64v/GWFtbA3s0jyWgwphKWzUcPHIYtzf//9X//v77//68+fP/vezbt+yNcrpfiKeL0uRbAXBqTE0IPLz0getuoBOLuqVUK/+ZlJA8cigHUq4LCgYKzVRwvei1kAuILXDEYT5rNJQ0/3++fnz58/f/7+3jsrm5W6dm4q923viGstzQYJQ01g2FkewtOqsFkKXW4+S6wQFHiGsit3giICwGrEqKrMLJcsElxCvPQat4gpWHR7Ptsmoqrun/vn+/75vnOXGOu6JFbV7RtGVZeBpSfO71993czcO5voPOFvtb8i9NcXHLPXrHJWFiIzrqtLaOZfTe33uu3wkLNNOb/fMNlw4XLe+77v3AljXdeKkJSZlTUpyl25k2gu6WpS0zS5MitzT/iHtPUCd5rhvDR1UmXMCU4BWA8gtpKSJMZY1yY+u73zOHQAIhPIrNxpW9Lruq7rotSMsVH1vu/vP9933Lkz27N+9DnMYC4i4qEuzy5x9HTB1QvMEKvs3NkCY82ZiqsyZzUHrNXIcHTDOWZ4r4w6EVRl5d6VSQwVXdcCWS6GXLVz47u5DTN3ZtVzyHOiGFKsiIgGmKdf0SXEmDge0vR0DR5BU3NodZ8DsGvY+ez6P+AB41KT1fu+7/vOTIkrFCGRdTbEBn5+9s+99f3dnVb/2AxidjNSRKy11pq1QTsCkREiNbJgCvCA1uPAKE+MyMqd6wppgHqMf7ffLApI3D/3z/d37n04dY//vhLK7u3M8OVzQMqPR6jlxOJ8g6STimbavdU+/H0MPbN7taYbsVXe2Pe9v4MR3cgjq98O+ATQBpCZ933TiItvPKg+ZvQ5b2dv63pj1zxL7z/4/F3lXtM9KPI+IDio1RLuaZbnmHWYY7Vwvk09RxvGcN6PHJyNh+2qFFWhqsydae+s3qy0RADQJj4/nn8453VnddXmF8x8oOIDC2dfyGcvCKyPtpwCr3I5setQ32c9fNZsv7aUhl2qe2+QZVLK6psdEBFiSIo+OuAgNI9CG6ScOfoYcpaM4Huv3puEERsd13Hg4/Ewyym7ps5+rnXa5eDqiL7Jc1Yh8zlV6eZbgy1t+KF/718A+gDVT18dn07kB1d51m4wCM+eep32msOrySkkG6aIEJco9dLKPbDHh2Hwx33OHpahOPX+NvxXkGycBWjD5unYfudHyU6YRJlQ4d2OiXcGDkXp4xYRKM/Rg0SFQu2CM+MRUDqjx0dIdbuex9CnjyO8f6X687nmuSQAjUrok13wLJ5sEfWu5YdK9GfQKwKgKA6VOreCAFKwb2k41s+BLHuKVw8THL12PPPvSvht/K+Z0DNKJynQ+xD9qD32sdb7sfjxbX3ng0XafcIxG5XWxw/0dXGEzvBn2dRhlMfYR2Cegnn65sP+OcV+7laZMTlRf8p/KDQ6R1WzYcRDp3kyKz+LEwAmgoQEUQz11nXgj8+uabZnH4L/GVn4BMPPx7MEOmU+Xo/cOJHH6VnN1KPtTOSJ1Tqmny2Sn69+cAYTdU7w36A0do8PgxsHXwH6d8H4Hapfvf/8MSeVg6BPtnyiSarpHW32DRAnA/yVtKcxHhH0/NtzRj6x+SC6v0PM9sD/Dv7nm3459MaDD397swSUob7u02TEm06PA5/j74DKxzA/CR2aBfaWvlCDzx2olkBzj8hjGk6BPFz5VyKez392/qzGVU0QB76Ho/QciFkC4/c3TeU9rfiB4hZbIfdqwMpeSSPrUNU29sNAf06j/svvr/XHRc/Hj8c2QQO9EgcLH1MCH4rs48fhOTgTnexqngwfpxqaCXqO71s/9px/m8fnx5vRn7+OrR967wNucTL4lEDVm9X3NeaY9WGYH8zoU7ocCmIAbnXSL3CKlBINGdX3Ss3zx4dhDAfN38PhlwfvR28hPKeUfNyx/QEYALB6BVKnvt/JGy/myPO85MHsOafxc0Nh3/PX72GfbXzE9qOLflnrf1reievMNpV8lkW/0OwxafTAv01/k7dfDp3bR8rlkigwDsTOHZd0ue80nJidzD0h968r/Q/OfJSBDRxd8g7BuzHXv7/t6bY3wg7KYu6pnKie+0CfyUDYJK3poNYg8O+kv9HhH5H7FagPljEl+S8fCABL/5+PHwpyGBZ7jOAxH3jvCclzP+sZKe8A+mBet+BRFE+/+ve1cYi+TxGc4gXAB6feiuz3KHmKsKevKJxRPOT5mPZmIO8wear2Y6Kg3CyyAbFF3y/M+Wf0xvpfT52Hz8BqOin8EjQexDqv6gT+ef6MapIQeqD0eqMXnOfWBo33eFC451rfyGB+SK5fSf/lzdyr+LztTQ6Otm6x+s8P/m97/De/sJbYhN0f2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x206D8758208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: truck\n",
      "Actual: ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x209889F99C8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: deer\n",
      "Actual: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x206D878DBC8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: dog\n",
      "Actual: dog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x209889F9CC8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: dog\n",
      "Actual: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x206D877A248>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reinitialize i\n",
    "i = rand_range - 5\n",
    "\n",
    "for i in range(i, rand_range):\n",
    "  print(\"Prediction: {}\".format(labels[pred[i]]))\n",
    "  print(\"Actual: {}\".format(labels[y_true[i]]))\n",
    "  pixels = new_x_test[i].reshape(64, 64, 3)\n",
    "  pixels = (pixels * 64) + 64\n",
    "  pixels = pixels.astype(np.uint8)\n",
    "\n",
    "  pic = Image.fromarray(pixels, 'RGB')\n",
    "  display(pic)\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "project3Noah.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
